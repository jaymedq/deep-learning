{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Titanic Survival Prediction\n",
        "\n",
        "This Jupyter Notebook covers the steps to predict Titanic survival using different machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 0.6389 - accuracy: 0.7301\n",
            "Epoch 2/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7847\n",
            "Epoch 3/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7938\n",
            "Epoch 4/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7961\n",
            "Epoch 5/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8052\n",
            "Epoch 6/50\n",
            "14/14 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.8030\n",
            "Epoch 7/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8109\n",
            "Epoch 8/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8064\n",
            "Epoch 9/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8098\n",
            "Epoch 10/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8109\n",
            "Epoch 11/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8098\n",
            "Epoch 12/50\n",
            "14/14 [==============================] - 0s 1ms/step - loss: 0.4197 - accuracy: 0.8166\n",
            "Epoch 13/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8109\n",
            "Epoch 14/50\n",
            "14/14 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8166\n",
            "Epoch 15/50\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8121\n",
            "Epoch 16/50\n",
            "14/14 [==============================] - 0s 1ms/step - loss: 0.4163 - accuracy: 0.8109\n",
            "Epoch 17/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8132\n",
            "Epoch 18/50\n",
            "14/14 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8132\n",
            "Epoch 19/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8235\n",
            "Epoch 20/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8257\n",
            "Epoch 21/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8246\n",
            "Epoch 22/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8189\n",
            "Epoch 23/50\n",
            "14/14 [==============================] - 0s 1ms/step - loss: 0.4079 - accuracy: 0.8257\n",
            "Epoch 24/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8007\n",
            "Epoch 25/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8178\n",
            "Epoch 26/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8098\n",
            "Epoch 27/50\n",
            "14/14 [==============================] - 0s 1ms/step - loss: 0.4059 - accuracy: 0.8212\n",
            "Epoch 28/50\n",
            "14/14 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8155\n",
            "Epoch 29/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8075\n",
            "Epoch 30/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8098\n",
            "Epoch 31/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8132\n",
            "Epoch 32/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8166\n",
            "Epoch 33/50\n",
            "14/14 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8189\n",
            "Epoch 34/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8200\n",
            "Epoch 35/50\n",
            "14/14 [==============================] - 0s 1ms/step - loss: 0.4001 - accuracy: 0.8269\n",
            "Epoch 36/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8235\n",
            "Epoch 37/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8269\n",
            "Epoch 38/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8269\n",
            "Epoch 39/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8212\n",
            "Epoch 40/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8235\n",
            "Epoch 41/50\n",
            "14/14 [==============================] - 0s 1ms/step - loss: 0.3962 - accuracy: 0.8280\n",
            "Epoch 42/50\n",
            "14/14 [==============================] - 0s 1ms/step - loss: 0.3964 - accuracy: 0.8235\n",
            "Epoch 43/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8314\n",
            "Epoch 44/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8235\n",
            "Epoch 45/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8269\n",
            "Epoch 46/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8269\n",
            "Epoch 47/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8223\n",
            "Epoch 48/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8349\n",
            "Epoch 49/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8223\n",
            "Epoch 50/50\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8235\n",
            "7/7 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.8000\n",
            "Model Accuracy: 0.800000011920929\n",
            "14/14 [==============================] - 0s 846us/step\n",
            "Test predictions saved to submission_keras_nn_with_smote.csv\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "train_data = pd.read_csv(\"dataset/train.csv\")\n",
        "test_data = pd.read_csv(\"dataset/test.csv\")\n",
        "\n",
        "# Data Preprocessing\n",
        "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\"]\n",
        "target = \"Survived\"\n",
        "\n",
        "def preprocess_data(df):\n",
        "    df[\"Age\"].fillna(df[\"Age\"].mean(), inplace=True)\n",
        "    df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
        "    df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"]\n",
        "    return df[features]\n",
        "\n",
        "X_train = preprocess_data(train_data)\n",
        "y_train = train_data[target]\n",
        "X_test = preprocess_data(test_data)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Apply SMOTE to balance the data\n",
        "smote = SMOTE(random_state=1)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Split the resampled data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_resampled, y_train_resampled, test_size=0.2, random_state=1)\n",
        "\n",
        "# Neural Network Model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, input_dim=X_train.shape[1], activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=64, verbose=1)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "_, accuracy = model.evaluate(X_val, y_val)\n",
        "print(f\"Model Accuracy: {accuracy}\")\n",
        "\n",
        "# Test the model on the test data\n",
        "test_predictions = (model.predict(X_test) > 0.7).astype(int).flatten()\n",
        "\n",
        "# Save the test predictions to a CSV file\n",
        "output = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": test_predictions})\n",
        "output.to_csv(\"submission_keras_nn_with_smote.csv\", index=False)\n",
        "print(\"Test predictions saved to submission_keras_nn_with_smote.csv\")\n",
        "\n",
        "# You can now submit the \"submission_keras_nn_with_smote.csv\" file to the Kaggle competition.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

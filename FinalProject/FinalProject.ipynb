{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to create a neural network capable of estimating DoA from telecommunications signals.\n",
    "\n",
    "To do so, the training dataset consists of In-Phase and Quadrature (IQ) samples and Angle of Arrival (AoA) measures.\n",
    "IQ samples consists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras import layers, models\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset path variable\n",
    "dataset_path = os.path.join(\n",
    "    os.getcwd(), \"Matlab\", \"bluetooth_signals_dataset_2024-02-19_20-03-25.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (IQ samples) and labels (Angles)\n",
    "X_complex_str = data.iloc[:, 1:].values.astype(str)\n",
    "y_str = data.iloc[:, 0].values\n",
    "\n",
    "# Convert string representations of complex numbers to actual complex values for features\n",
    "X_complex = np.array([np.complex128(complex(val.replace('i', 'j'))) for row in X_complex_str for val in row])\n",
    "X_complex = X_complex.reshape(X_complex_str.shape)\n",
    "\n",
    "# Separate real and imaginary parts for features\n",
    "X_real = np.real(X_complex)\n",
    "X_imag = np.imag(X_complex)\n",
    "\n",
    "# Combine real and imaginary parts into a single array for features\n",
    "X_combined = np.stack((X_real, X_imag), axis=-1)\n",
    "\n",
    "# Convert string representations of complex numbers to actual complex values for labels\n",
    "y_complex = np.array([np.complex128(complex(val.replace('i', 'j'))) for val in y_str])\n",
    "\n",
    "# Use only the real part for labels\n",
    "y = np.real(y_complex)\n",
    "\n",
    "# Split the combined data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the input data\n",
    "scaler = StandardScaler()\n",
    "X_train_flat = X_train.reshape((-1, 16))\n",
    "X_test_flat = X_test.reshape((-1, 16))\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_test_scaled = scaler.transform(X_test_flat)\n",
    "X_train = X_train_scaled.reshape((-1, 4, 4, 2))\n",
    "X_test = X_test_scaled.reshape((-1, 4, 4, 2))\n",
    "\n",
    "# Model architecture\n",
    "model = models.Sequential()\n",
    "# Tentar mudar a arquitetura: uma camada inical maior, 2 camadas convolucionais, etc.\n",
    "# Tentar um dataset com menos angulos, ao invÃ©s de 361 entre -180 e 180, de 5 em 5.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(4, 4, 2)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='linear'))  # Linear activation for regression\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We'll use the `ModelCheckpoint` callback to regularly save checkpoints, and\n",
    "the `EarlyStopping` callback to interrupt training when the validation loss\n",
    "is not longer improving.\n",
    "\"\"\"\n",
    "\n",
    "path_checkpoint = \"aoa_model_checkpoint.weights.h5\"\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=10, restore_best_weights=True)\n",
    "\n",
    "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/217 [=========================>....] - ETA: 0s - loss: 10872.5146 - mae: 90.2660\n",
      "Epoch 1: val_loss improved from inf to 10261.64258, saving model to aoa_model_checkpoint.weights.h5\n",
      "217/217 [==============================] - 1s 2ms/step - loss: 10917.5762 - mae: 90.4904 - val_loss: 10261.6426 - val_mae: 87.0405\n",
      "Epoch 2/20\n",
      "214/217 [============================>.] - ETA: 0s - loss: 10916.3457 - mae: 90.4786\n",
      "Epoch 2: val_loss did not improve from 10261.64258\n",
      "217/217 [==============================] - 0s 2ms/step - loss: 10915.9062 - mae: 90.4820 - val_loss: 10262.1250 - val_mae: 87.0397\n",
      "Epoch 3/20\n",
      "193/217 [=========================>....] - ETA: 0s - loss: 10874.0527 - mae: 90.2126\n",
      "Epoch 3: val_loss did not improve from 10261.64258\n",
      "217/217 [==============================] - 0s 2ms/step - loss: 10914.0283 - mae: 90.4742 - val_loss: 10262.9092 - val_mae: 87.0421\n",
      "Epoch 4/20\n",
      "201/217 [==========================>...] - ETA: 0s - loss: 10926.7041 - mae: 90.6067\n",
      "Epoch 4: val_loss improved from 10261.64258 to 10260.35156, saving model to aoa_model_checkpoint.weights.h5\n",
      "217/217 [==============================] - 0s 2ms/step - loss: 10911.7998 - mae: 90.4650 - val_loss: 10260.3516 - val_mae: 87.0318\n",
      "Epoch 5/20\n",
      "194/217 [=========================>....] - ETA: 0s - loss: 10965.5293 - mae: 90.7794\n",
      "Epoch 5: val_loss did not improve from 10260.35156\n",
      "217/217 [==============================] - 0s 2ms/step - loss: 10908.3652 - mae: 90.4442 - val_loss: 10263.0156 - val_mae: 87.0486\n",
      "Epoch 6/20\n",
      "212/217 [============================>.] - ETA: 0s - loss: 10914.4756 - mae: 90.4562\n",
      "Epoch 6: val_loss improved from 10260.35156 to 10256.04199, saving model to aoa_model_checkpoint.weights.h5\n",
      "217/217 [==============================] - 0s 2ms/step - loss: 10906.0732 - mae: 90.4441 - val_loss: 10256.0420 - val_mae: 87.0146\n",
      "Epoch 7/20\n",
      "206/217 [===========================>..] - ETA: 0s - loss: 10945.0420 - mae: 90.6281\n",
      "Epoch 7: val_loss improved from 10256.04199 to 10250.71582, saving model to aoa_model_checkpoint.weights.h5\n",
      "217/217 [==============================] - 0s 2ms/step - loss: 10902.4912 - mae: 90.4132 - val_loss: 10250.7158 - val_mae: 86.9639\n",
      "Epoch 8/20\n",
      "213/217 [============================>.] - ETA: 0s - loss: 10875.4307 - mae: 90.2429\n",
      "Epoch 8: val_loss did not improve from 10250.71582\n",
      "217/217 [==============================] - 0s 1ms/step - loss: 10901.8994 - mae: 90.4108 - val_loss: 10260.9902 - val_mae: 87.0326\n",
      "Epoch 9/20\n",
      "173/217 [======================>.......] - ETA: 0s - loss: 10853.6172 - mae: 90.0606\n",
      "Epoch 9: val_loss did not improve from 10250.71582\n",
      "217/217 [==============================] - 0s 1ms/step - loss: 10898.1855 - mae: 90.3812 - val_loss: 10259.4414 - val_mae: 87.0240\n",
      "Epoch 10/20\n",
      "182/217 [========================>.....] - ETA: 0s - loss: 10893.5586 - mae: 90.3478\n",
      "Epoch 10: val_loss did not improve from 10250.71582\n",
      "217/217 [==============================] - 0s 1ms/step - loss: 10894.5059 - mae: 90.3653 - val_loss: 10251.8340 - val_mae: 86.9726\n",
      "Epoch 11/20\n",
      "205/217 [===========================>..] - ETA: 0s - loss: 10887.7754 - mae: 90.3828\n",
      "Epoch 11: val_loss did not improve from 10250.71582\n",
      "217/217 [==============================] - 0s 2ms/step - loss: 10893.9785 - mae: 90.3666 - val_loss: 10254.7324 - val_mae: 86.9830\n",
      "Epoch 12/20\n",
      "201/217 [==========================>...] - ETA: 0s - loss: 10875.2314 - mae: 90.2025\n",
      "Epoch 12: val_loss improved from 10250.71582 to 10241.98145, saving model to aoa_model_checkpoint.weights.h5\n",
      "217/217 [==============================] - 0s 2ms/step - loss: 10888.7920 - mae: 90.3204 - val_loss: 10241.9814 - val_mae: 86.9120\n",
      "Epoch 13/20\n",
      "205/217 [===========================>..] - ETA: 0s - loss: 10861.6309 - mae: 90.2356\n",
      "Epoch 13: val_loss did not improve from 10241.98145\n",
      "217/217 [==============================] - 0s 2ms/step - loss: 10888.5518 - mae: 90.3335 - val_loss: 10244.0078 - val_mae: 86.9189\n",
      "Epoch 14/20\n",
      "201/217 [==========================>...] - ETA: 0s - loss: 10886.3867 - mae: 90.3299\n",
      "Epoch 14: val_loss did not improve from 10241.98145\n",
      "217/217 [==============================] - 0s 2ms/step - loss: 10883.5010 - mae: 90.2909 - val_loss: 10254.5508 - val_mae: 86.9667\n",
      "Epoch 15/20\n",
      "205/217 [===========================>..] - ETA: 0s - loss: 10863.9277 - mae: 90.1903\n",
      "Epoch 15: val_loss improved from 10241.98145 to 10241.96875, saving model to aoa_model_checkpoint.weights.h5\n",
      "217/217 [==============================] - 0s 2ms/step - loss: 10880.6484 - mae: 90.2758 - val_loss: 10241.9688 - val_mae: 86.8818\n",
      "Epoch 16/20\n",
      "213/217 [============================>.] - ETA: 0s - loss: 10862.3535 - mae: 90.1797\n",
      "Epoch 16: val_loss improved from 10241.96875 to 10239.24219, saving model to aoa_model_checkpoint.weights.h5\n",
      "217/217 [==============================] - 0s 2ms/step - loss: 10878.6504 - mae: 90.2765 - val_loss: 10239.2422 - val_mae: 86.8700\n",
      "Epoch 17/20\n",
      "204/217 [===========================>..] - ETA: 0s - loss: 10883.0879 - mae: 90.3459\n",
      "Epoch 17: val_loss did not improve from 10239.24219\n",
      "217/217 [==============================] - 0s 2ms/step - loss: 10874.9502 - mae: 90.2552 - val_loss: 10239.2461 - val_mae: 86.8688\n",
      "Epoch 18/20\n",
      "177/217 [=======================>......] - ETA: 0s - loss: 10796.7637 - mae: 89.7941\n",
      "Epoch 18: val_loss did not improve from 10239.24219\n",
      "217/217 [==============================] - 0s 1ms/step - loss: 10869.5283 - mae: 90.2320 - val_loss: 10247.2109 - val_mae: 86.8949\n",
      "Epoch 19/20\n",
      "179/217 [=======================>......] - ETA: 0s - loss: 10953.9668 - mae: 90.7083\n",
      "Epoch 19: val_loss did not improve from 10239.24219\n",
      "217/217 [==============================] - 0s 1ms/step - loss: 10866.0879 - mae: 90.1941 - val_loss: 10249.1924 - val_mae: 86.9030\n",
      "Epoch 20/20\n",
      "177/217 [=======================>......] - ETA: 0s - loss: 10856.1211 - mae: 90.0122\n",
      "Epoch 20: val_loss did not improve from 10239.24219\n",
      "217/217 [==============================] - 0s 1ms/step - loss: 10865.5723 - mae: 90.1978 - val_loss: 10266.1533 - val_mae: 86.9662\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11174.4209 - mae: 92.1350\n",
      "Mean Absolute Error on Test Set: 92.13497924804688\n",
      "68/68 [==============================] - 0s 941us/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, validation_split=0.2, callbacks=[es_callback, modelckpt_callback])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Mean Absolute Error on Test Set: {mae}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34495637],\n",
       "       [-0.40295032],\n",
       "       [ 0.17824353],\n",
       "       ...,\n",
       "       [ 0.48004445],\n",
       "       [-0.29392853],\n",
       "       [ 0.5742067 ]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

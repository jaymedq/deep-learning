{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to create a neural network capable of estimating DoA from telecommunications signals.\n",
    "\n",
    "To do so, the training dataset consists of In-Phase and Quadrature (IQ) samples and Angle of Arrival (AoA) measures.\n",
    "IQ samples consists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras import layers, models\n",
    "import os\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset path variable\n",
    "dataset_path = os.path.join(\n",
    "    os.getcwd(), \"Matlab\", \"bluetooth_signals_dataset2024-02-05_22-56-11.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (IQ samples) and labels (Angles)\n",
    "X_complex_str = data.iloc[:, 1:].values.astype(str)\n",
    "y_str = data.iloc[:, 0].values\n",
    "\n",
    "# Convert string representations of complex numbers to actual complex values for features\n",
    "X_complex = np.array([np.complex128(complex(val.replace('i', 'j'))) for row in X_complex_str for val in row])\n",
    "X_complex = X_complex.reshape(X_complex_str.shape)\n",
    "\n",
    "# Separate real and imaginary parts for features\n",
    "X_real = np.real(X_complex)\n",
    "X_imag = np.imag(X_complex)\n",
    "\n",
    "# Combine real and imaginary parts into a single array for features\n",
    "X_combined = np.stack((X_real, X_imag), axis=-1)\n",
    "\n",
    "# Convert string representations of complex numbers to actual complex values for labels\n",
    "y_complex = np.array([np.complex128(complex(val.replace('i', 'j'))) for val in y_str])\n",
    "\n",
    "# Use only the real part for labels\n",
    "y = np.real(y_complex)\n",
    "\n",
    "# Split the combined data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the input data\n",
    "scaler = StandardScaler()\n",
    "X_train_flat = X_train.reshape((-1, 16))\n",
    "X_test_flat = X_test.reshape((-1, 16))\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_test_scaled = scaler.transform(X_test_flat)\n",
    "X_train = X_train_scaled.reshape((-1, 4, 4, 2))\n",
    "X_test = X_test_scaled.reshape((-1, 4, 4, 2))\n",
    "\n",
    "# Model architecture\n",
    "model = models.Sequential()\n",
    "# Tentar mudar a arquitetura: uma camada inical maior, 2 camadas convolucionais, etc.\n",
    "# Tentar um dataset com menos angulos, ao inv√©s de 361 entre -90 e 90, de 5 em 5.\n",
    "model.add(layers.Conv2D(16, (2, 2), activation='relu', input_shape=(4, 4, 2)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(36, activation='relu'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We'll use the `ModelCheckpoint` callback to regularly save checkpoints, and\n",
    "the `EarlyStopping` callback to interrupt training when the validation loss\n",
    "is not longer improving.\n",
    "\"\"\"\n",
    "\n",
    "path_checkpoint = \"aoa_model_checkpoint.weights.h5\"\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor=\"mae\", min_delta=0, patience=50, restore_best_weights=True)\n",
    "\n",
    "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"mae\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 10104.1562 - mae: 86.0546 - val_loss: 11437.0068 - val_mae: 93.3794\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10103.4883 - mae: 86.0515 - val_loss: 11436.7607 - val_mae: 93.3808\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10102.6738 - mae: 86.0478 - val_loss: 11436.4590 - val_mae: 93.3822\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10101.7725 - mae: 86.0429 - val_loss: 11436.2607 - val_mae: 93.3830\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10101.0361 - mae: 86.0398 - val_loss: 11435.5430 - val_mae: 93.3837\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10099.7656 - mae: 86.0327 - val_loss: 11434.9961 - val_mae: 93.3835\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10098.6377 - mae: 86.0277 - val_loss: 11434.6426 - val_mae: 93.3828\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10097.7324 - mae: 86.0226 - val_loss: 11433.6895 - val_mae: 93.3826\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10096.0469 - mae: 86.0137 - val_loss: 11433.7334 - val_mae: 93.3832\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 10095.2090 - mae: 86.0093 - val_loss: 11433.9180 - val_mae: 93.3841\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10094.0869 - mae: 86.0029 - val_loss: 11433.0947 - val_mae: 93.3845\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10091.9160 - mae: 85.9933 - val_loss: 11432.5039 - val_mae: 93.3849\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10089.6543 - mae: 85.9808 - val_loss: 11431.6123 - val_mae: 93.3875\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10087.0098 - mae: 85.9662 - val_loss: 11430.0625 - val_mae: 93.3897\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10083.6885 - mae: 85.9475 - val_loss: 11427.2998 - val_mae: 93.3903\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10077.0205 - mae: 85.9122 - val_loss: 11425.4072 - val_mae: 93.3940\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10072.2959 - mae: 85.8839 - val_loss: 11422.9375 - val_mae: 93.3965\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10068.7080 - mae: 85.8660 - val_loss: 11421.1914 - val_mae: 93.4000\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10063.7754 - mae: 85.8412 - val_loss: 11419.4678 - val_mae: 93.3931\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10059.5088 - mae: 85.8158 - val_loss: 11418.3311 - val_mae: 93.3898\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10056.0879 - mae: 85.7958 - val_loss: 11416.6875 - val_mae: 93.3826\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10050.0898 - mae: 85.7647 - val_loss: 11416.3193 - val_mae: 93.3873\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10045.6123 - mae: 85.7369 - val_loss: 11417.5811 - val_mae: 93.3921\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10041.7002 - mae: 85.7193 - val_loss: 11416.3613 - val_mae: 93.3885\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10037.0693 - mae: 85.6970 - val_loss: 11415.2617 - val_mae: 93.3868\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10031.4072 - mae: 85.6691 - val_loss: 11415.3535 - val_mae: 93.3895\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10029.0811 - mae: 85.6582 - val_loss: 11413.7158 - val_mae: 93.3914\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10019.6035 - mae: 85.6107 - val_loss: 11416.5977 - val_mae: 93.4057\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10015.0293 - mae: 85.5839 - val_loss: 11417.8574 - val_mae: 93.4197\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 10007.9209 - mae: 85.5304 - val_loss: 11421.2891 - val_mae: 93.4541\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 10000.6943 - mae: 85.4901 - val_loss: 11420.9551 - val_mae: 93.4907\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9997.3936 - mae: 85.4583 - val_loss: 11421.4785 - val_mae: 93.5578\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9986.9336 - mae: 85.4068 - val_loss: 11430.4521 - val_mae: 93.6174\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9983.4238 - mae: 85.3897 - val_loss: 11436.7021 - val_mae: 93.6443\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9976.6641 - mae: 85.3544 - val_loss: 11439.9980 - val_mae: 93.7178\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 9972.0215 - mae: 85.3347 - val_loss: 11446.3447 - val_mae: 93.7663\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9965.0371 - mae: 85.2967 - val_loss: 11451.0898 - val_mae: 93.7790\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9958.7129 - mae: 85.2665 - val_loss: 11457.7354 - val_mae: 93.8014\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9953.0137 - mae: 85.2403 - val_loss: 11458.8086 - val_mae: 93.7708\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9954.7559 - mae: 85.2654 - val_loss: 11465.5088 - val_mae: 93.8010\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9946.1191 - mae: 85.2259 - val_loss: 11465.5811 - val_mae: 93.7756\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9942.0303 - mae: 85.2028 - val_loss: 11462.0342 - val_mae: 93.7354\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9941.5400 - mae: 85.1880 - val_loss: 11466.5215 - val_mae: 93.7543\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9935.4062 - mae: 85.1563 - val_loss: 11471.7529 - val_mae: 93.7958\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9931.6885 - mae: 85.1459 - val_loss: 11479.9062 - val_mae: 93.8375\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9925.4717 - mae: 85.1168 - val_loss: 11486.4873 - val_mae: 93.8767\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9921.0928 - mae: 85.0902 - val_loss: 11493.7393 - val_mae: 93.9227\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9918.4922 - mae: 85.0750 - val_loss: 11494.6865 - val_mae: 93.9337\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9910.0176 - mae: 85.0371 - val_loss: 11488.9785 - val_mae: 93.9069\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9911.5840 - mae: 85.0446 - val_loss: 11481.0859 - val_mae: 93.8564\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9907.9209 - mae: 85.0311 - val_loss: 11478.3984 - val_mae: 93.8338\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9900.2314 - mae: 85.0198 - val_loss: 11492.1055 - val_mae: 93.9176\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9894.0557 - mae: 84.9740 - val_loss: 11493.5723 - val_mae: 93.9285\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9889.7217 - mae: 84.9466 - val_loss: 11497.2295 - val_mae: 93.9491\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9884.4111 - mae: 84.9161 - val_loss: 11502.8145 - val_mae: 93.9737\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9878.7900 - mae: 84.8886 - val_loss: 11506.1621 - val_mae: 93.9942\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9883.0000 - mae: 84.8821 - val_loss: 11515.5479 - val_mae: 94.0480\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9870.7051 - mae: 84.8497 - val_loss: 11509.0273 - val_mae: 94.0154\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9864.8311 - mae: 84.8162 - val_loss: 11513.1211 - val_mae: 94.0104\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9860.2266 - mae: 84.7986 - val_loss: 11511.7373 - val_mae: 94.0029\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9853.9453 - mae: 84.7735 - val_loss: 11505.8359 - val_mae: 93.9891\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9847.9053 - mae: 84.7478 - val_loss: 11500.9053 - val_mae: 93.9489\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9846.4121 - mae: 84.7416 - val_loss: 11496.5996 - val_mae: 93.9221\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9839.7910 - mae: 84.7138 - val_loss: 11503.1904 - val_mae: 93.9491\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9840.8467 - mae: 84.7128 - val_loss: 11517.2803 - val_mae: 94.0212\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9829.7490 - mae: 84.6581 - val_loss: 11513.6035 - val_mae: 94.0160\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9825.5615 - mae: 84.6224 - val_loss: 11518.6504 - val_mae: 94.0480\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9816.6348 - mae: 84.5740 - val_loss: 11514.2617 - val_mae: 94.0291\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9811.5254 - mae: 84.5614 - val_loss: 11510.0283 - val_mae: 94.0122\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9805.6826 - mae: 84.5329 - val_loss: 11521.0752 - val_mae: 94.0653\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9797.8848 - mae: 84.4908 - val_loss: 11518.4160 - val_mae: 94.0634\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9791.2041 - mae: 84.4598 - val_loss: 11513.7646 - val_mae: 94.0576\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9785.5000 - mae: 84.4202 - val_loss: 11515.2197 - val_mae: 94.0635\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9782.4424 - mae: 84.4199 - val_loss: 11506.4746 - val_mae: 94.0041\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9775.6543 - mae: 84.3949 - val_loss: 11507.2188 - val_mae: 93.9985\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9771.8154 - mae: 84.3832 - val_loss: 11511.5479 - val_mae: 94.0195\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9763.2314 - mae: 84.3340 - val_loss: 11520.4004 - val_mae: 94.0611\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9766.4863 - mae: 84.3520 - val_loss: 11532.0645 - val_mae: 94.1261\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9755.8740 - mae: 84.2879 - val_loss: 11519.8770 - val_mae: 94.0702\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9747.5840 - mae: 84.2494 - val_loss: 11501.6699 - val_mae: 93.9501\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9751.2021 - mae: 84.3008 - val_loss: 11505.8320 - val_mae: 93.9691\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9738.9619 - mae: 84.2312 - val_loss: 11523.0088 - val_mae: 94.0687\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9734.4961 - mae: 84.1800 - val_loss: 11532.7773 - val_mae: 94.1165\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9729.0791 - mae: 84.1530 - val_loss: 11537.7900 - val_mae: 94.1432\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9725.8936 - mae: 84.1436 - val_loss: 11528.5957 - val_mae: 94.0811\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9716.9365 - mae: 84.0974 - val_loss: 11540.4053 - val_mae: 94.1316\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9710.2793 - mae: 84.0742 - val_loss: 11542.2070 - val_mae: 94.1456\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9704.1426 - mae: 84.0509 - val_loss: 11538.3125 - val_mae: 94.1168\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9699.9531 - mae: 84.0348 - val_loss: 11527.6484 - val_mae: 94.0451\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9692.9678 - mae: 83.9896 - val_loss: 11536.9971 - val_mae: 94.1042\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9694.0195 - mae: 83.9911 - val_loss: 11548.6582 - val_mae: 94.1705\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9687.8184 - mae: 83.9650 - val_loss: 11543.6074 - val_mae: 94.1474\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9679.5371 - mae: 83.9374 - val_loss: 11537.9814 - val_mae: 94.1029\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9671.7285 - mae: 83.9074 - val_loss: 11540.8037 - val_mae: 94.1034\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9673.9023 - mae: 83.8855 - val_loss: 11568.8652 - val_mae: 94.2410\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9672.7344 - mae: 83.8624 - val_loss: 11559.7832 - val_mae: 94.2027\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9662.6152 - mae: 83.8084 - val_loss: 11559.8291 - val_mae: 94.2102\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9658.7148 - mae: 83.7993 - val_loss: 11561.0381 - val_mae: 94.2207\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9655.1650 - mae: 83.8032 - val_loss: 11547.7627 - val_mae: 94.1462\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9647.1895 - mae: 83.7635 - val_loss: 11556.6797 - val_mae: 94.2078\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9640.5830 - mae: 83.7632 - val_loss: 11549.2754 - val_mae: 94.1652\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9632.9766 - mae: 83.7438 - val_loss: 11546.9121 - val_mae: 94.1456\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9624.9326 - mae: 83.6944 - val_loss: 11551.2080 - val_mae: 94.1511\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 9624.2520 - mae: 83.6575 - val_loss: 11567.0293 - val_mae: 94.2235\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9622.7227 - mae: 83.6414 - val_loss: 11582.3672 - val_mae: 94.2993\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9622.2900 - mae: 83.6378 - val_loss: 11599.9502 - val_mae: 94.3802\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9624.0742 - mae: 83.6242 - val_loss: 11592.1885 - val_mae: 94.3419\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9599.7324 - mae: 83.5455 - val_loss: 11542.4980 - val_mae: 94.0830\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9611.9912 - mae: 83.6727 - val_loss: 11520.8623 - val_mae: 93.9455\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9597.9922 - mae: 83.6401 - val_loss: 11542.1211 - val_mae: 94.0647\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9587.4443 - mae: 83.5695 - val_loss: 11555.9053 - val_mae: 94.1268\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9585.2627 - mae: 83.5579 - val_loss: 11546.7324 - val_mae: 94.0805\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9574.0615 - mae: 83.5147 - val_loss: 11555.2412 - val_mae: 94.1320\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9568.4209 - mae: 83.4848 - val_loss: 11574.1279 - val_mae: 94.2179\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9571.5352 - mae: 83.5002 - val_loss: 11572.7354 - val_mae: 94.2356\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9554.6143 - mae: 83.4384 - val_loss: 11552.0508 - val_mae: 94.1342\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9553.8467 - mae: 83.4295 - val_loss: 11543.8115 - val_mae: 94.0858\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9546.3301 - mae: 83.4322 - val_loss: 11560.9297 - val_mae: 94.1651\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9543.1553 - mae: 83.4166 - val_loss: 11579.7627 - val_mae: 94.2469\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9541.8447 - mae: 83.3763 - val_loss: 11577.2246 - val_mae: 94.2584\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9541.9229 - mae: 83.3238 - val_loss: 11523.2812 - val_mae: 93.9954\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9534.9824 - mae: 83.3532 - val_loss: 11523.8408 - val_mae: 93.9901\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9527.8516 - mae: 83.3075 - val_loss: 11567.8750 - val_mae: 94.1887\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9525.9219 - mae: 83.2824 - val_loss: 11605.4355 - val_mae: 94.3449\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9517.3174 - mae: 83.2413 - val_loss: 11572.2412 - val_mae: 94.2181\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9504.7686 - mae: 83.2207 - val_loss: 11566.8760 - val_mae: 94.1827\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9503.4648 - mae: 83.2666 - val_loss: 11527.0400 - val_mae: 93.9667\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9506.8184 - mae: 83.2900 - val_loss: 11540.8086 - val_mae: 94.0170\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9494.3828 - mae: 83.2491 - val_loss: 11573.5928 - val_mae: 94.1330\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9498.2158 - mae: 83.2453 - val_loss: 11589.2275 - val_mae: 94.1960\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9487.6240 - mae: 83.1984 - val_loss: 11552.2334 - val_mae: 94.0404\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9477.0264 - mae: 83.1532 - val_loss: 11545.7217 - val_mae: 93.9888\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9477.8945 - mae: 83.1924 - val_loss: 11526.6865 - val_mae: 93.8863\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9474.3730 - mae: 83.1482 - val_loss: 11536.1885 - val_mae: 93.9291\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9463.1816 - mae: 83.0975 - val_loss: 11566.0996 - val_mae: 94.0588\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9457.1895 - mae: 83.0747 - val_loss: 11574.5898 - val_mae: 94.0900\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9454.8955 - mae: 83.0677 - val_loss: 11593.2959 - val_mae: 94.1550\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9451.2217 - mae: 83.0635 - val_loss: 11572.6641 - val_mae: 94.0953\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9443.7100 - mae: 83.0407 - val_loss: 11539.6006 - val_mae: 93.9510\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9444.8018 - mae: 83.0537 - val_loss: 11529.3096 - val_mae: 93.9226\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9458.1211 - mae: 83.1211 - val_loss: 11577.9473 - val_mae: 94.1187\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9433.3213 - mae: 82.9909 - val_loss: 11555.5088 - val_mae: 94.0113\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9424.3838 - mae: 82.9371 - val_loss: 11577.1934 - val_mae: 94.0738\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9435.7812 - mae: 82.9778 - val_loss: 11628.5664 - val_mae: 94.2505\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9425.5703 - mae: 82.9467 - val_loss: 11599.2041 - val_mae: 94.1264\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9411.5605 - mae: 82.9148 - val_loss: 11577.1016 - val_mae: 94.0384\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9407.5869 - mae: 82.8653 - val_loss: 11561.2119 - val_mae: 93.9516\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9407.0127 - mae: 82.8477 - val_loss: 11541.2695 - val_mae: 93.8549\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9401.2178 - mae: 82.8355 - val_loss: 11560.3291 - val_mae: 93.9387\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9396.7920 - mae: 82.8264 - val_loss: 11599.3838 - val_mae: 94.0926\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9402.9443 - mae: 82.8188 - val_loss: 11606.0957 - val_mae: 94.0982\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9385.2471 - mae: 82.7408 - val_loss: 11580.1113 - val_mae: 93.9762\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9383.0166 - mae: 82.7450 - val_loss: 11556.0205 - val_mae: 93.8734\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9375.5908 - mae: 82.7167 - val_loss: 11572.7568 - val_mae: 93.9458\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9367.4297 - mae: 82.6913 - val_loss: 11577.9355 - val_mae: 93.9692\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9362.7734 - mae: 82.6625 - val_loss: 11583.8408 - val_mae: 93.9855\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9356.9336 - mae: 82.6428 - val_loss: 11574.8926 - val_mae: 93.9432\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9358.1064 - mae: 82.6722 - val_loss: 11553.3926 - val_mae: 93.8630\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9351.3965 - mae: 82.6300 - val_loss: 11593.9443 - val_mae: 94.0246\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9344.7627 - mae: 82.5884 - val_loss: 11617.8359 - val_mae: 94.1063\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9344.4736 - mae: 82.5642 - val_loss: 11628.0791 - val_mae: 94.1312\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9341.9258 - mae: 82.5379 - val_loss: 11625.3252 - val_mae: 94.1336\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9327.4961 - mae: 82.5144 - val_loss: 11569.3809 - val_mae: 93.9213\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9325.2920 - mae: 82.5455 - val_loss: 11552.5059 - val_mae: 93.8656\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9322.1953 - mae: 82.5416 - val_loss: 11561.1240 - val_mae: 93.8811\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9324.5381 - mae: 82.5421 - val_loss: 11575.4141 - val_mae: 93.9400\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9318.5576 - mae: 82.5012 - val_loss: 11662.5195 - val_mae: 94.2311\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9317.7715 - mae: 82.4866 - val_loss: 11625.7412 - val_mae: 94.1277\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9299.7051 - mae: 82.4190 - val_loss: 11606.9395 - val_mae: 94.0533\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9307.8750 - mae: 82.4081 - val_loss: 11620.1807 - val_mae: 94.0790\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9295.0234 - mae: 82.3845 - val_loss: 11591.6074 - val_mae: 93.9946\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9286.1982 - mae: 82.3653 - val_loss: 11593.4043 - val_mae: 94.0107\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9276.8818 - mae: 82.3208 - val_loss: 11591.5166 - val_mae: 93.9988\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9275.5771 - mae: 82.2927 - val_loss: 11578.2178 - val_mae: 93.9350\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9274.4863 - mae: 82.3023 - val_loss: 11532.6055 - val_mae: 93.7429\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9264.4287 - mae: 82.2311 - val_loss: 11593.5068 - val_mae: 93.9411\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9264.2363 - mae: 82.2132 - val_loss: 11610.0205 - val_mae: 93.9976\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9255.3447 - mae: 82.1938 - val_loss: 11608.6484 - val_mae: 93.9799\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9256.0166 - mae: 82.2144 - val_loss: 11616.6768 - val_mae: 93.9905\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9249.6641 - mae: 82.1922 - val_loss: 11571.0859 - val_mae: 93.7995\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9243.0156 - mae: 82.1975 - val_loss: 11624.9766 - val_mae: 93.9747\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9237.7861 - mae: 82.1675 - val_loss: 11619.1787 - val_mae: 93.9658\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9226.8594 - mae: 82.0940 - val_loss: 11592.5967 - val_mae: 93.8902\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9224.4902 - mae: 82.0810 - val_loss: 11596.4717 - val_mae: 93.9094\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9219.4414 - mae: 82.0584 - val_loss: 11592.7666 - val_mae: 93.9051\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9227.4971 - mae: 82.1450 - val_loss: 11575.7178 - val_mae: 93.8112\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9216.7891 - mae: 82.0914 - val_loss: 11600.6895 - val_mae: 93.8600\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9209.9248 - mae: 82.0777 - val_loss: 11601.1885 - val_mae: 93.8603\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9204.4961 - mae: 82.0405 - val_loss: 11606.4678 - val_mae: 93.8988\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9195.8848 - mae: 81.9968 - val_loss: 11614.4414 - val_mae: 93.9208\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9200.1123 - mae: 81.9657 - val_loss: 11579.4717 - val_mae: 93.7569\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9186.5439 - mae: 81.9131 - val_loss: 11613.7422 - val_mae: 93.9199\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9184.1152 - mae: 81.8921 - val_loss: 11622.3428 - val_mae: 93.9907\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9181.6230 - mae: 81.8721 - val_loss: 11633.3467 - val_mae: 94.0393\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9170.8242 - mae: 81.8534 - val_loss: 11580.7783 - val_mae: 93.8373\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 9166.0889 - mae: 81.8426 - val_loss: 11573.5166 - val_mae: 93.7972\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9162.1367 - mae: 81.8416 - val_loss: 11585.1104 - val_mae: 93.8120\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9159.6025 - mae: 81.8784 - val_loss: 11572.8320 - val_mae: 93.7450\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9148.7666 - mae: 81.8210 - val_loss: 11581.0996 - val_mae: 93.7771\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9142.5205 - mae: 81.7826 - val_loss: 11602.8057 - val_mae: 93.8726\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9135.9268 - mae: 81.7559 - val_loss: 11579.4805 - val_mae: 93.7762\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9139.1934 - mae: 81.7764 - val_loss: 11546.6133 - val_mae: 93.6253\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9128.0518 - mae: 81.6706 - val_loss: 11559.0068 - val_mae: 93.6812\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9130.1738 - mae: 81.7208 - val_loss: 11553.2207 - val_mae: 93.6690\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9120.0518 - mae: 81.6784 - val_loss: 11613.7363 - val_mae: 93.9431\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9115.3818 - mae: 81.6635 - val_loss: 11622.2373 - val_mae: 93.9733\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9103.5098 - mae: 81.5942 - val_loss: 11594.4688 - val_mae: 93.8423\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9093.8662 - mae: 81.5399 - val_loss: 11535.8887 - val_mae: 93.5870\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9109.4814 - mae: 81.6202 - val_loss: 11561.5303 - val_mae: 93.6517\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9094.9453 - mae: 81.5335 - val_loss: 11622.3135 - val_mae: 93.8907\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9101.8584 - mae: 81.5283 - val_loss: 11693.9746 - val_mae: 94.1711\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9095.6562 - mae: 81.4705 - val_loss: 11667.4180 - val_mae: 94.1391\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9081.2373 - mae: 81.4490 - val_loss: 11630.7568 - val_mae: 93.9986\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9074.5391 - mae: 81.4493 - val_loss: 11560.3359 - val_mae: 93.7174\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9081.4219 - mae: 81.4677 - val_loss: 11584.4961 - val_mae: 93.8086\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9062.7637 - mae: 81.3653 - val_loss: 11598.3086 - val_mae: 93.8515\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9053.7920 - mae: 81.3326 - val_loss: 11625.4316 - val_mae: 93.9210\n",
      "Epoch 218/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9054.1348 - mae: 81.3110 - val_loss: 11664.3877 - val_mae: 94.0588\n",
      "Epoch 219/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9051.0889 - mae: 81.3253 - val_loss: 11602.1562 - val_mae: 93.8037\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9038.3018 - mae: 81.2903 - val_loss: 11614.5137 - val_mae: 93.8400\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9030.7920 - mae: 81.2729 - val_loss: 11637.1211 - val_mae: 93.9268\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9027.2090 - mae: 81.2402 - val_loss: 11641.1787 - val_mae: 93.9672\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9028.1357 - mae: 81.2151 - val_loss: 11641.8584 - val_mae: 93.9838\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9021.0811 - mae: 81.1901 - val_loss: 11624.6162 - val_mae: 93.9044\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9018.8057 - mae: 81.2261 - val_loss: 11636.8945 - val_mae: 93.9174\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9014.4990 - mae: 81.2249 - val_loss: 11628.2393 - val_mae: 93.8492\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9009.1162 - mae: 81.1323 - val_loss: 11663.0107 - val_mae: 94.0118\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9005.2275 - mae: 81.0625 - val_loss: 11649.7891 - val_mae: 93.9861\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8998.9814 - mae: 81.0770 - val_loss: 11625.1768 - val_mae: 93.8553\n",
      "Epoch 230/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8990.6982 - mae: 81.0302 - val_loss: 11668.2695 - val_mae: 94.0188\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8995.4824 - mae: 81.0552 - val_loss: 11689.1338 - val_mae: 94.0873\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8996.7617 - mae: 81.0689 - val_loss: 11628.0752 - val_mae: 93.8604\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8975.3691 - mae: 80.9336 - val_loss: 11665.0391 - val_mae: 93.9589\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8973.0732 - mae: 80.9123 - val_loss: 11673.7979 - val_mae: 94.0045\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8971.2764 - mae: 80.9068 - val_loss: 11678.4805 - val_mae: 94.0443\n",
      "Epoch 236/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8956.7617 - mae: 80.8419 - val_loss: 11648.4854 - val_mae: 93.9463\n",
      "Epoch 237/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8956.7100 - mae: 80.8737 - val_loss: 11627.0645 - val_mae: 93.7993\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8957.8271 - mae: 80.9002 - val_loss: 11683.8105 - val_mae: 94.0152\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8955.3584 - mae: 80.8399 - val_loss: 11701.7090 - val_mae: 94.1114\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8950.8525 - mae: 80.7737 - val_loss: 11676.2998 - val_mae: 94.0533\n",
      "Epoch 241/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8941.3809 - mae: 80.7397 - val_loss: 11704.3135 - val_mae: 94.1522\n",
      "Epoch 242/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8941.4561 - mae: 80.7475 - val_loss: 11698.4785 - val_mae: 94.1368\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8934.5391 - mae: 80.7220 - val_loss: 11674.8555 - val_mae: 94.0170\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8922.6074 - mae: 80.6699 - val_loss: 11686.9678 - val_mae: 94.0699\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8918.7197 - mae: 80.6656 - val_loss: 11696.8721 - val_mae: 94.1145\n",
      "Epoch 246/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8911.5400 - mae: 80.6454 - val_loss: 11683.9346 - val_mae: 94.0275\n",
      "Epoch 247/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8915.2236 - mae: 80.6576 - val_loss: 11660.2705 - val_mae: 93.8672\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8913.3145 - mae: 80.6565 - val_loss: 11668.0605 - val_mae: 93.9004\n",
      "Epoch 249/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8920.7178 - mae: 80.7084 - val_loss: 11637.3750 - val_mae: 93.7606\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8895.7578 - mae: 80.5618 - val_loss: 11709.0215 - val_mae: 94.0135\n",
      "Epoch 251/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8911.9307 - mae: 80.6027 - val_loss: 11731.0088 - val_mae: 94.1163\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8884.3975 - mae: 80.4431 - val_loss: 11662.8213 - val_mae: 93.9097\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8909.5693 - mae: 80.6428 - val_loss: 11623.0195 - val_mae: 93.7559\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8883.7959 - mae: 80.5232 - val_loss: 11717.8730 - val_mae: 94.0992\n",
      "Epoch 255/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8871.9600 - mae: 80.4193 - val_loss: 11749.5723 - val_mae: 94.2270\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8870.3467 - mae: 80.4004 - val_loss: 11674.6104 - val_mae: 93.9465\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8867.5439 - mae: 80.4151 - val_loss: 11664.7871 - val_mae: 93.8916\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8858.7275 - mae: 80.4234 - val_loss: 11699.8838 - val_mae: 93.9826\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8860.6387 - mae: 80.4497 - val_loss: 11706.3428 - val_mae: 94.0423\n",
      "Epoch 260/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8852.1309 - mae: 80.4195 - val_loss: 11678.5176 - val_mae: 93.9390\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8853.7002 - mae: 80.3763 - val_loss: 11724.4863 - val_mae: 94.1143\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8837.3135 - mae: 80.2407 - val_loss: 11708.8750 - val_mae: 94.0350\n",
      "Epoch 263/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8833.3877 - mae: 80.2294 - val_loss: 11736.6348 - val_mae: 94.1459\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8830.0273 - mae: 80.1792 - val_loss: 11745.7998 - val_mae: 94.1926\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8821.0908 - mae: 80.1727 - val_loss: 11702.4453 - val_mae: 94.0282\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8819.8799 - mae: 80.1760 - val_loss: 11713.3760 - val_mae: 94.0242\n",
      "Epoch 267/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8809.1865 - mae: 80.1278 - val_loss: 11747.5693 - val_mae: 94.1249\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8815.5625 - mae: 80.0898 - val_loss: 11766.1533 - val_mae: 94.2089\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8798.9150 - mae: 80.1225 - val_loss: 11689.8857 - val_mae: 94.0414\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8801.5898 - mae: 80.1207 - val_loss: 11729.8086 - val_mae: 94.1944\n",
      "Epoch 271/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8794.0586 - mae: 80.0820 - val_loss: 11757.6621 - val_mae: 94.2157\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8789.2344 - mae: 80.0340 - val_loss: 11765.8037 - val_mae: 94.1986\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8786.8555 - mae: 79.9733 - val_loss: 11787.9883 - val_mae: 94.2672\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8782.2090 - mae: 79.9054 - val_loss: 11757.6523 - val_mae: 94.1646\n",
      "Epoch 275/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8773.4590 - mae: 79.8355 - val_loss: 11768.6357 - val_mae: 94.1994\n",
      "Epoch 276/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8764.2764 - mae: 79.8493 - val_loss: 11738.2070 - val_mae: 94.0784\n",
      "Epoch 277/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8758.1182 - mae: 79.8360 - val_loss: 11767.6992 - val_mae: 94.1113\n",
      "Epoch 278/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8758.5693 - mae: 79.8016 - val_loss: 11788.7842 - val_mae: 94.2381\n",
      "Epoch 279/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8753.7891 - mae: 79.7708 - val_loss: 11719.2480 - val_mae: 94.0399\n",
      "Epoch 280/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8750.9092 - mae: 79.7228 - val_loss: 11754.0557 - val_mae: 94.1422\n",
      "Epoch 281/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8742.5850 - mae: 79.7270 - val_loss: 11769.5996 - val_mae: 94.1852\n",
      "Epoch 282/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8729.8047 - mae: 79.6692 - val_loss: 11785.0859 - val_mae: 94.2198\n",
      "Epoch 283/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8729.8496 - mae: 79.5775 - val_loss: 11821.3818 - val_mae: 94.3542\n",
      "Epoch 284/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8724.9404 - mae: 79.6125 - val_loss: 11787.4180 - val_mae: 94.2742\n",
      "Epoch 285/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8724.4463 - mae: 79.6490 - val_loss: 11793.6680 - val_mae: 94.2893\n",
      "Epoch 286/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8704.7783 - mae: 79.5044 - val_loss: 11862.4473 - val_mae: 94.5091\n",
      "Epoch 287/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8712.8691 - mae: 79.5059 - val_loss: 11818.4033 - val_mae: 94.3334\n",
      "Epoch 288/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8710.3125 - mae: 79.5448 - val_loss: 11697.7734 - val_mae: 93.9641\n",
      "Epoch 289/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8728.4912 - mae: 79.6209 - val_loss: 11690.9678 - val_mae: 93.9050\n",
      "Epoch 290/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8711.3359 - mae: 79.5204 - val_loss: 11769.7500 - val_mae: 94.1018\n",
      "Epoch 291/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8687.6328 - mae: 79.3475 - val_loss: 11812.8047 - val_mae: 94.2457\n",
      "Epoch 292/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8679.3242 - mae: 79.3368 - val_loss: 11825.0449 - val_mae: 94.3267\n",
      "Epoch 293/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8673.0234 - mae: 79.3312 - val_loss: 11834.0625 - val_mae: 94.3534\n",
      "Epoch 294/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8670.5723 - mae: 79.3086 - val_loss: 11810.3467 - val_mae: 94.2413\n",
      "Epoch 295/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8686.3955 - mae: 79.4920 - val_loss: 11773.9785 - val_mae: 94.1134\n",
      "Epoch 296/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8662.8643 - mae: 79.3335 - val_loss: 11878.3203 - val_mae: 94.4723\n",
      "Epoch 297/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8682.5332 - mae: 79.3745 - val_loss: 11945.4004 - val_mae: 94.7525\n",
      "Epoch 298/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8662.3262 - mae: 79.2642 - val_loss: 11863.7012 - val_mae: 94.3407\n",
      "Epoch 299/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8643.5762 - mae: 79.1548 - val_loss: 11884.4766 - val_mae: 94.4344\n",
      "Epoch 300/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8647.4541 - mae: 79.1756 - val_loss: 11926.2842 - val_mae: 94.6044\n",
      "Epoch 301/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8647.2578 - mae: 79.1536 - val_loss: 11825.0000 - val_mae: 94.1920\n",
      "Epoch 302/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8633.5156 - mae: 79.1375 - val_loss: 11841.5947 - val_mae: 94.2687\n",
      "Epoch 303/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8628.3857 - mae: 79.1297 - val_loss: 11840.7959 - val_mae: 94.2495\n",
      "Epoch 304/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8619.7148 - mae: 79.0555 - val_loss: 11861.2646 - val_mae: 94.3193\n",
      "Epoch 305/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8613.4648 - mae: 78.9925 - val_loss: 11911.1680 - val_mae: 94.5114\n",
      "Epoch 306/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 8622.3037 - mae: 79.0030 - val_loss: 11935.8555 - val_mae: 94.6029\n",
      "Epoch 307/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8610.9912 - mae: 78.9066 - val_loss: 11862.3770 - val_mae: 94.3038\n",
      "Epoch 308/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8608.5830 - mae: 78.8932 - val_loss: 11899.9746 - val_mae: 94.4478\n",
      "Epoch 309/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8608.5420 - mae: 78.9283 - val_loss: 11896.6104 - val_mae: 94.4841\n",
      "Epoch 310/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8591.7490 - mae: 78.8702 - val_loss: 11919.4414 - val_mae: 94.5812\n",
      "Epoch 311/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8587.5459 - mae: 78.8478 - val_loss: 11914.8037 - val_mae: 94.5704\n",
      "Epoch 312/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8580.2393 - mae: 78.8166 - val_loss: 11949.2881 - val_mae: 94.6998\n",
      "Epoch 313/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8576.9453 - mae: 78.7993 - val_loss: 11950.5068 - val_mae: 94.7146\n",
      "Epoch 314/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8569.1621 - mae: 78.7461 - val_loss: 11982.0820 - val_mae: 94.8160\n",
      "Epoch 315/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8569.8447 - mae: 78.6867 - val_loss: 11969.4414 - val_mae: 94.7026\n",
      "Epoch 316/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8580.2012 - mae: 78.7514 - val_loss: 11916.6943 - val_mae: 94.5281\n",
      "Epoch 317/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8559.5098 - mae: 78.6078 - val_loss: 12005.4570 - val_mae: 94.8299\n",
      "Epoch 318/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8555.1992 - mae: 78.6555 - val_loss: 11957.4355 - val_mae: 94.6505\n",
      "Epoch 319/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8567.8135 - mae: 78.7407 - val_loss: 11846.3955 - val_mae: 94.2246\n",
      "Epoch 320/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8559.3740 - mae: 78.7052 - val_loss: 11940.7246 - val_mae: 94.5563\n",
      "Epoch 321/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8538.9873 - mae: 78.5267 - val_loss: 11969.5732 - val_mae: 94.6380\n",
      "Epoch 322/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8537.1553 - mae: 78.5032 - val_loss: 11971.8877 - val_mae: 94.6585\n",
      "Epoch 323/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8531.4658 - mae: 78.4632 - val_loss: 12009.5977 - val_mae: 94.7954\n",
      "Epoch 324/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8527.5557 - mae: 78.4181 - val_loss: 12025.8018 - val_mae: 94.8792\n",
      "Epoch 325/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8525.0947 - mae: 78.3802 - val_loss: 12016.2588 - val_mae: 94.8457\n",
      "Epoch 326/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8524.6133 - mae: 78.4013 - val_loss: 11994.5928 - val_mae: 94.7944\n",
      "Epoch 327/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8513.1191 - mae: 78.3928 - val_loss: 11983.7783 - val_mae: 94.7236\n",
      "Epoch 328/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8515.3203 - mae: 78.4086 - val_loss: 11988.3857 - val_mae: 94.7035\n",
      "Epoch 329/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8501.4561 - mae: 78.3075 - val_loss: 12058.4033 - val_mae: 95.0008\n",
      "Epoch 330/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8504.2998 - mae: 78.2541 - val_loss: 12020.9209 - val_mae: 94.8271\n",
      "Epoch 331/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8496.6455 - mae: 78.2313 - val_loss: 11983.3525 - val_mae: 94.6856\n",
      "Epoch 332/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8493.1855 - mae: 78.2036 - val_loss: 12011.9678 - val_mae: 94.8107\n",
      "Epoch 333/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 8487.9531 - mae: 78.1616 - val_loss: 12003.8008 - val_mae: 94.8021\n",
      "Epoch 334/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8481.2285 - mae: 78.1184 - val_loss: 12054.6729 - val_mae: 95.0202\n",
      "Epoch 335/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8493.1934 - mae: 78.1593 - val_loss: 12050.5615 - val_mae: 95.0002\n",
      "Epoch 336/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8495.0039 - mae: 78.2643 - val_loss: 11914.0176 - val_mae: 94.6148\n",
      "Epoch 337/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8515.4355 - mae: 78.4758 - val_loss: 11937.2979 - val_mae: 94.6812\n",
      "Epoch 338/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8470.2891 - mae: 78.1802 - val_loss: 12047.2266 - val_mae: 94.9618\n",
      "Epoch 339/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8496.1572 - mae: 78.1620 - val_loss: 12185.0039 - val_mae: 95.4404\n",
      "Epoch 340/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8476.8213 - mae: 78.0732 - val_loss: 11989.1729 - val_mae: 94.7472\n",
      "Epoch 341/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8466.0371 - mae: 78.1001 - val_loss: 12006.9873 - val_mae: 94.8278\n",
      "Epoch 342/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8456.9512 - mae: 78.0435 - val_loss: 12014.3945 - val_mae: 94.8284\n",
      "Epoch 343/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8457.6924 - mae: 78.0033 - val_loss: 12059.6445 - val_mae: 94.9755\n",
      "Epoch 344/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8443.7998 - mae: 77.9076 - val_loss: 12062.3789 - val_mae: 94.9289\n",
      "Epoch 345/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8441.7656 - mae: 77.8988 - val_loss: 12028.3301 - val_mae: 94.8023\n",
      "Epoch 346/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8438.3945 - mae: 77.9190 - val_loss: 12078.7109 - val_mae: 95.0005\n",
      "Epoch 347/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8433.0010 - mae: 77.8843 - val_loss: 12115.1055 - val_mae: 95.1285\n",
      "Epoch 348/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8425.2168 - mae: 77.8592 - val_loss: 12082.9268 - val_mae: 94.9981\n",
      "Epoch 349/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8420.7158 - mae: 77.7982 - val_loss: 12124.2959 - val_mae: 95.0688\n",
      "Epoch 350/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8426.5479 - mae: 77.7484 - val_loss: 12164.0107 - val_mae: 95.1966\n",
      "Epoch 351/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8411.1992 - mae: 77.7221 - val_loss: 12056.7393 - val_mae: 94.7933\n",
      "Epoch 352/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8419.0449 - mae: 77.8304 - val_loss: 12082.6289 - val_mae: 94.8940\n",
      "Epoch 353/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8420.9912 - mae: 77.7757 - val_loss: 12247.5645 - val_mae: 95.5574\n",
      "Epoch 354/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8422.0576 - mae: 77.6886 - val_loss: 12149.6455 - val_mae: 95.1737\n",
      "Epoch 355/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8397.8691 - mae: 77.7224 - val_loss: 12041.9453 - val_mae: 94.8692\n",
      "Epoch 356/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8418.9248 - mae: 77.8964 - val_loss: 12054.8359 - val_mae: 94.9048\n",
      "Epoch 357/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8402.7900 - mae: 77.7808 - val_loss: 12073.0928 - val_mae: 94.8314\n",
      "Epoch 358/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8386.2686 - mae: 77.5728 - val_loss: 12156.9033 - val_mae: 95.1273\n",
      "Epoch 359/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8385.7373 - mae: 77.5173 - val_loss: 12135.5410 - val_mae: 95.0279\n",
      "Epoch 360/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8373.1455 - mae: 77.4733 - val_loss: 12091.1211 - val_mae: 94.8693\n",
      "Epoch 361/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8380.1064 - mae: 77.5450 - val_loss: 12138.3682 - val_mae: 95.1017\n",
      "Epoch 362/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8369.9395 - mae: 77.5008 - val_loss: 12087.7568 - val_mae: 94.9302\n",
      "Epoch 363/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8393.7275 - mae: 77.7013 - val_loss: 12047.2627 - val_mae: 94.8595\n",
      "Epoch 364/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8387.7432 - mae: 77.6666 - val_loss: 12105.4199 - val_mae: 95.0108\n",
      "Epoch 365/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8363.3926 - mae: 77.4713 - val_loss: 12191.4248 - val_mae: 95.3666\n",
      "Epoch 366/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8357.5840 - mae: 77.3495 - val_loss: 12157.9629 - val_mae: 95.1657\n",
      "Epoch 367/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8356.5137 - mae: 77.3328 - val_loss: 12163.5303 - val_mae: 95.1766\n",
      "Epoch 368/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8355.9785 - mae: 77.3657 - val_loss: 12078.6162 - val_mae: 94.8941\n",
      "Epoch 369/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8361.2588 - mae: 77.4862 - val_loss: 12089.6387 - val_mae: 94.9708\n",
      "Epoch 370/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8361.9180 - mae: 77.5309 - val_loss: 12108.1582 - val_mae: 95.0289\n",
      "Epoch 371/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8358.2676 - mae: 77.4111 - val_loss: 12187.0908 - val_mae: 95.2753\n",
      "Epoch 372/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8339.4268 - mae: 77.2217 - val_loss: 12136.4062 - val_mae: 95.0777\n",
      "Epoch 373/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8336.8496 - mae: 77.2235 - val_loss: 12148.3057 - val_mae: 95.0846\n",
      "Epoch 374/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8332.4199 - mae: 77.2300 - val_loss: 12181.4648 - val_mae: 95.1942\n",
      "Epoch 375/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8334.0469 - mae: 77.2562 - val_loss: 12197.9678 - val_mae: 95.2686\n",
      "Epoch 376/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8320.6357 - mae: 77.1293 - val_loss: 12237.1543 - val_mae: 95.4202\n",
      "Epoch 377/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8321.1279 - mae: 77.1060 - val_loss: 12202.2314 - val_mae: 95.2786\n",
      "Epoch 378/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8320.5459 - mae: 77.1515 - val_loss: 12240.7090 - val_mae: 95.4549\n",
      "Epoch 379/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8311.8301 - mae: 77.0625 - val_loss: 12285.7783 - val_mae: 95.6644\n",
      "Epoch 380/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8310.2852 - mae: 77.0425 - val_loss: 12195.6787 - val_mae: 95.2852\n",
      "Epoch 381/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8313.2529 - mae: 77.0075 - val_loss: 12261.5176 - val_mae: 95.6104\n",
      "Epoch 382/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8305.8691 - mae: 76.9560 - val_loss: 12272.2412 - val_mae: 95.6567\n",
      "Epoch 383/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8292.8828 - mae: 76.9565 - val_loss: 12217.6133 - val_mae: 95.3935\n",
      "Epoch 384/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8304.7793 - mae: 77.0956 - val_loss: 12250.5322 - val_mae: 95.5504\n",
      "Epoch 385/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8307.6406 - mae: 76.9915 - val_loss: 12341.7480 - val_mae: 95.9239\n",
      "Epoch 386/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8298.4336 - mae: 76.9291 - val_loss: 12275.0859 - val_mae: 95.6465\n",
      "Epoch 387/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8287.1992 - mae: 76.8912 - val_loss: 12259.1885 - val_mae: 95.5860\n",
      "Epoch 388/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 8274.1240 - mae: 76.7795 - val_loss: 12311.8516 - val_mae: 95.8111\n",
      "Epoch 389/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8289.5693 - mae: 76.8835 - val_loss: 12281.8613 - val_mae: 95.6715\n",
      "Epoch 390/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8275.1123 - mae: 76.8510 - val_loss: 12305.1943 - val_mae: 95.7741\n",
      "Epoch 391/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8270.8428 - mae: 76.8463 - val_loss: 12285.8555 - val_mae: 95.6724\n",
      "Epoch 392/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8270.7949 - mae: 76.8410 - val_loss: 12326.1230 - val_mae: 95.8318\n",
      "Epoch 393/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8266.6934 - mae: 76.7535 - val_loss: 12348.2412 - val_mae: 95.9124\n",
      "Epoch 394/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8262.4521 - mae: 76.7174 - val_loss: 12342.3809 - val_mae: 95.8897\n",
      "Epoch 395/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8255.2031 - mae: 76.6498 - val_loss: 12364.7627 - val_mae: 95.9858\n",
      "Epoch 396/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8251.4971 - mae: 76.6326 - val_loss: 12333.3809 - val_mae: 95.8594\n",
      "Epoch 397/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8251.7461 - mae: 76.6650 - val_loss: 12340.2695 - val_mae: 95.8975\n",
      "Epoch 398/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 8247.8359 - mae: 76.6440 - val_loss: 12317.1523 - val_mae: 95.7629\n",
      "Epoch 399/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8245.4219 - mae: 76.6559 - val_loss: 12255.7900 - val_mae: 95.4517\n",
      "Epoch 400/1000\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 8255.8564 - mae: 76.6189 - val_loss: 12304.5908 - val_mae: 95.6783\n",
      "Epoch 401/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8262.5977 - mae: 76.7646 - val_loss: 12223.1357 - val_mae: 95.3537\n",
      "Epoch 402/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8244.8701 - mae: 76.5725 - val_loss: 12401.1592 - val_mae: 96.0889\n",
      "Epoch 403/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8249.4561 - mae: 76.4928 - val_loss: 12395.9199 - val_mae: 96.0812\n",
      "Epoch 404/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8234.5898 - mae: 76.5115 - val_loss: 12296.7158 - val_mae: 95.6793\n",
      "Epoch 405/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 8239.0342 - mae: 76.6227 - val_loss: 12289.4229 - val_mae: 95.6435\n",
      "Epoch 406/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8232.1699 - mae: 76.4874 - val_loss: 12355.8340 - val_mae: 95.9231\n",
      "Epoch 407/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8224.4395 - mae: 76.4438 - val_loss: 12330.4961 - val_mae: 95.7862\n",
      "Epoch 408/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8223.4053 - mae: 76.3646 - val_loss: 12409.5977 - val_mae: 96.0930\n",
      "Epoch 409/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8226.4893 - mae: 76.4222 - val_loss: 12319.1338 - val_mae: 95.6787\n",
      "Epoch 410/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8216.3916 - mae: 76.4181 - val_loss: 12431.1592 - val_mae: 96.1855\n",
      "Epoch 411/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8212.8594 - mae: 76.3148 - val_loss: 12369.8232 - val_mae: 95.9082\n",
      "Epoch 412/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8213.2246 - mae: 76.4222 - val_loss: 12314.5537 - val_mae: 95.6948\n",
      "Epoch 413/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8206.7539 - mae: 76.3521 - val_loss: 12353.3457 - val_mae: 95.8692\n",
      "Epoch 414/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8200.1904 - mae: 76.2948 - val_loss: 12350.1934 - val_mae: 95.8538\n",
      "Epoch 415/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8197.0566 - mae: 76.2650 - val_loss: 12391.3359 - val_mae: 96.0124\n",
      "Epoch 416/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8197.6270 - mae: 76.1762 - val_loss: 12474.3828 - val_mae: 96.3511\n",
      "Epoch 417/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8206.2686 - mae: 76.2193 - val_loss: 12505.0029 - val_mae: 96.4517\n",
      "Epoch 418/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8189.9009 - mae: 76.1888 - val_loss: 12405.4570 - val_mae: 96.0201\n",
      "Epoch 419/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8183.5928 - mae: 76.1490 - val_loss: 12395.0068 - val_mae: 95.9853\n",
      "Epoch 420/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8185.2905 - mae: 76.0552 - val_loss: 12474.3857 - val_mae: 96.3269\n",
      "Epoch 421/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8187.6211 - mae: 76.0637 - val_loss: 12402.9658 - val_mae: 96.0317\n",
      "Epoch 422/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8174.9893 - mae: 76.0818 - val_loss: 12438.3945 - val_mae: 96.1632\n",
      "Epoch 423/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8169.4199 - mae: 76.0086 - val_loss: 12454.0322 - val_mae: 96.2161\n",
      "Epoch 424/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8168.1167 - mae: 76.0111 - val_loss: 12440.4004 - val_mae: 96.1531\n",
      "Epoch 425/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8166.4995 - mae: 75.9537 - val_loss: 12469.6230 - val_mae: 96.2347\n",
      "Epoch 426/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8165.6021 - mae: 76.0783 - val_loss: 12421.3730 - val_mae: 96.0491\n",
      "Epoch 427/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8167.8262 - mae: 76.1128 - val_loss: 12477.0449 - val_mae: 96.3081\n",
      "Epoch 428/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8158.8169 - mae: 76.0113 - val_loss: 12475.3877 - val_mae: 96.2873\n",
      "Epoch 429/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8179.9009 - mae: 76.0975 - val_loss: 12621.5537 - val_mae: 96.8885\n",
      "Epoch 430/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8156.0244 - mae: 75.9195 - val_loss: 12427.2461 - val_mae: 96.1223\n",
      "Epoch 431/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8154.7544 - mae: 75.9823 - val_loss: 12407.0811 - val_mae: 96.0998\n",
      "Epoch 432/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8149.3242 - mae: 75.8910 - val_loss: 12476.2158 - val_mae: 96.3446\n",
      "Epoch 433/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8149.3667 - mae: 75.8491 - val_loss: 12491.5703 - val_mae: 96.3946\n",
      "Epoch 434/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8143.8057 - mae: 75.8260 - val_loss: 12546.5342 - val_mae: 96.5871\n",
      "Epoch 435/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8140.7607 - mae: 75.8058 - val_loss: 12540.6377 - val_mae: 96.5040\n",
      "Epoch 436/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8138.1104 - mae: 75.8586 - val_loss: 12529.3516 - val_mae: 96.4845\n",
      "Epoch 437/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8134.5859 - mae: 75.8375 - val_loss: 12488.0693 - val_mae: 96.2969\n",
      "Epoch 438/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8128.5918 - mae: 75.7940 - val_loss: 12419.5732 - val_mae: 96.0156\n",
      "Epoch 439/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8128.7544 - mae: 75.8119 - val_loss: 12452.2607 - val_mae: 96.1174\n",
      "Epoch 440/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 8116.2471 - mae: 75.6801 - val_loss: 12538.5479 - val_mae: 96.4644\n",
      "Epoch 441/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8118.1758 - mae: 75.6901 - val_loss: 12552.7881 - val_mae: 96.5090\n",
      "Epoch 442/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8111.7461 - mae: 75.6637 - val_loss: 12569.8545 - val_mae: 96.5761\n",
      "Epoch 443/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8105.4663 - mae: 75.5962 - val_loss: 12559.0752 - val_mae: 96.5397\n",
      "Epoch 444/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8103.0474 - mae: 75.5895 - val_loss: 12580.6289 - val_mae: 96.6200\n",
      "Epoch 445/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8105.6919 - mae: 75.5615 - val_loss: 12545.2627 - val_mae: 96.4983\n",
      "Epoch 446/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8099.0947 - mae: 75.5160 - val_loss: 12565.0645 - val_mae: 96.5766\n",
      "Epoch 447/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8096.2383 - mae: 75.4798 - val_loss: 12551.0820 - val_mae: 96.5183\n",
      "Epoch 448/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8090.1211 - mae: 75.4455 - val_loss: 12605.1650 - val_mae: 96.7378\n",
      "Epoch 449/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8106.7842 - mae: 75.4925 - val_loss: 12691.8613 - val_mae: 97.0617\n",
      "Epoch 450/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8092.6191 - mae: 75.4095 - val_loss: 12451.2939 - val_mae: 96.1128\n",
      "Epoch 451/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8094.6450 - mae: 75.4915 - val_loss: 12447.7070 - val_mae: 96.0805\n",
      "Epoch 452/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8084.1006 - mae: 75.3547 - val_loss: 12576.7949 - val_mae: 96.5848\n",
      "Epoch 453/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8085.4746 - mae: 75.2939 - val_loss: 12547.8818 - val_mae: 96.4502\n",
      "Epoch 454/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8072.0776 - mae: 75.3212 - val_loss: 12470.5078 - val_mae: 96.1273\n",
      "Epoch 455/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8079.7710 - mae: 75.4553 - val_loss: 12472.0273 - val_mae: 96.1254\n",
      "Epoch 456/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8069.5991 - mae: 75.3485 - val_loss: 12563.8467 - val_mae: 96.5062\n",
      "Epoch 457/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8069.1245 - mae: 75.3226 - val_loss: 12591.1553 - val_mae: 96.6242\n",
      "Epoch 458/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8061.1094 - mae: 75.2463 - val_loss: 12585.5957 - val_mae: 96.5636\n",
      "Epoch 459/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8059.2500 - mae: 75.2455 - val_loss: 12538.2090 - val_mae: 96.3548\n",
      "Epoch 460/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8055.2021 - mae: 75.2575 - val_loss: 12601.7070 - val_mae: 96.6036\n",
      "Epoch 461/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8059.0693 - mae: 75.1992 - val_loss: 12622.2285 - val_mae: 96.6324\n",
      "Epoch 462/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8054.7246 - mae: 75.2086 - val_loss: 12595.9922 - val_mae: 96.5122\n",
      "Epoch 463/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8054.2275 - mae: 75.1951 - val_loss: 12697.5020 - val_mae: 96.9121\n",
      "Epoch 464/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8033.3384 - mae: 75.0954 - val_loss: 12562.7822 - val_mae: 96.3649\n",
      "Epoch 465/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8045.9546 - mae: 75.2965 - val_loss: 12523.0742 - val_mae: 96.2065\n",
      "Epoch 466/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8051.7920 - mae: 75.3432 - val_loss: 12558.8320 - val_mae: 96.3818\n",
      "Epoch 467/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8041.0908 - mae: 75.2275 - val_loss: 12620.4521 - val_mae: 96.6709\n",
      "Epoch 468/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8040.4985 - mae: 75.1573 - val_loss: 12664.4629 - val_mae: 96.8301\n",
      "Epoch 469/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8029.9517 - mae: 75.0431 - val_loss: 12615.3613 - val_mae: 96.6689\n",
      "Epoch 470/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8035.3794 - mae: 75.1690 - val_loss: 12567.9180 - val_mae: 96.5242\n",
      "Epoch 471/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8029.7495 - mae: 75.1626 - val_loss: 12690.3760 - val_mae: 96.9467\n",
      "Epoch 472/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8024.8877 - mae: 74.9949 - val_loss: 12682.7783 - val_mae: 96.8907\n",
      "Epoch 473/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8018.5942 - mae: 74.9354 - val_loss: 12588.8496 - val_mae: 96.5810\n",
      "Epoch 474/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8025.8452 - mae: 75.0381 - val_loss: 12567.4893 - val_mae: 96.4973\n",
      "Epoch 475/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 8019.4409 - mae: 75.0173 - val_loss: 12676.7891 - val_mae: 96.8517\n",
      "Epoch 476/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8008.2798 - mae: 74.9297 - val_loss: 12720.0479 - val_mae: 97.0090\n",
      "Epoch 477/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8006.6714 - mae: 74.8588 - val_loss: 12631.1328 - val_mae: 96.6780\n",
      "Epoch 478/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8030.5664 - mae: 75.1518 - val_loss: 12521.4414 - val_mae: 96.2944\n",
      "Epoch 479/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8021.0898 - mae: 75.1103 - val_loss: 12648.9180 - val_mae: 96.7546\n",
      "Epoch 480/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7999.8633 - mae: 74.8096 - val_loss: 12668.2588 - val_mae: 96.8085\n",
      "Epoch 481/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8008.8857 - mae: 74.7945 - val_loss: 12663.1250 - val_mae: 96.7704\n",
      "Epoch 482/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7993.0820 - mae: 74.8905 - val_loss: 12585.7891 - val_mae: 96.3746\n",
      "Epoch 483/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8017.2588 - mae: 75.0875 - val_loss: 12631.3789 - val_mae: 96.5380\n",
      "Epoch 484/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7982.5107 - mae: 74.7308 - val_loss: 12762.7793 - val_mae: 97.0120\n",
      "Epoch 485/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8001.6250 - mae: 74.6338 - val_loss: 12699.0254 - val_mae: 96.7438\n",
      "Epoch 486/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7990.7207 - mae: 74.6276 - val_loss: 12666.5215 - val_mae: 96.6395\n",
      "Epoch 487/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7976.2349 - mae: 74.7064 - val_loss: 12765.4658 - val_mae: 97.1074\n",
      "Epoch 488/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8003.7817 - mae: 74.9690 - val_loss: 12843.8447 - val_mae: 97.4271\n",
      "Epoch 489/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7986.5288 - mae: 74.7146 - val_loss: 12789.1289 - val_mae: 97.1797\n",
      "Epoch 490/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7989.2568 - mae: 74.7551 - val_loss: 12608.7520 - val_mae: 96.5305\n",
      "Epoch 491/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7975.1768 - mae: 74.6832 - val_loss: 12762.3164 - val_mae: 97.0680\n",
      "Epoch 492/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 7970.6196 - mae: 74.5592 - val_loss: 12815.1807 - val_mae: 97.2882\n",
      "Epoch 493/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7970.0781 - mae: 74.6175 - val_loss: 12803.8682 - val_mae: 97.2539\n",
      "Epoch 494/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7963.7339 - mae: 74.5715 - val_loss: 12804.8252 - val_mae: 97.2294\n",
      "Epoch 495/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7959.2935 - mae: 74.5995 - val_loss: 12715.9707 - val_mae: 96.8460\n",
      "Epoch 496/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7964.4082 - mae: 74.7203 - val_loss: 12647.7871 - val_mae: 96.5651\n",
      "Epoch 497/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7958.1436 - mae: 74.6274 - val_loss: 12722.4316 - val_mae: 96.8306\n",
      "Epoch 498/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7964.0913 - mae: 74.4574 - val_loss: 12857.3955 - val_mae: 97.2915\n",
      "Epoch 499/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7953.7114 - mae: 74.3321 - val_loss: 12779.3574 - val_mae: 96.9743\n",
      "Epoch 500/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7949.7495 - mae: 74.4335 - val_loss: 12726.3525 - val_mae: 96.7856\n",
      "Epoch 501/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7946.9346 - mae: 74.4163 - val_loss: 12732.2441 - val_mae: 96.8123\n",
      "Epoch 502/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7942.6636 - mae: 74.3246 - val_loss: 12912.1113 - val_mae: 97.5216\n",
      "Epoch 503/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7951.3193 - mae: 74.3991 - val_loss: 12805.0869 - val_mae: 97.0672\n",
      "Epoch 504/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7930.4751 - mae: 74.2795 - val_loss: 12857.4678 - val_mae: 97.2433\n",
      "Epoch 505/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7957.8472 - mae: 74.3673 - val_loss: 12916.7148 - val_mae: 97.4542\n",
      "Epoch 506/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7941.4512 - mae: 74.4188 - val_loss: 12787.4287 - val_mae: 96.9663\n",
      "Epoch 507/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7933.0171 - mae: 74.3043 - val_loss: 12834.4629 - val_mae: 97.1231\n",
      "Epoch 508/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7926.7949 - mae: 74.1219 - val_loss: 12923.8877 - val_mae: 97.4548\n",
      "Epoch 509/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7932.3809 - mae: 74.2506 - val_loss: 12863.5215 - val_mae: 97.2270\n",
      "Epoch 510/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7941.6440 - mae: 74.3269 - val_loss: 12932.7305 - val_mae: 97.4875\n",
      "Epoch 511/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7911.7075 - mae: 74.1043 - val_loss: 12793.2607 - val_mae: 96.9786\n",
      "Epoch 512/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 7917.0366 - mae: 74.1428 - val_loss: 12802.1836 - val_mae: 96.9870\n",
      "Epoch 513/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7926.7119 - mae: 74.2772 - val_loss: 12753.3252 - val_mae: 96.8493\n",
      "Epoch 514/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7909.8047 - mae: 74.2073 - val_loss: 12847.1445 - val_mae: 97.1809\n",
      "Epoch 515/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7904.9761 - mae: 74.0778 - val_loss: 12875.6104 - val_mae: 97.2389\n",
      "Epoch 516/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7912.4751 - mae: 74.1053 - val_loss: 12739.9268 - val_mae: 96.6998\n",
      "Epoch 517/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7899.2559 - mae: 74.0454 - val_loss: 12845.8164 - val_mae: 97.1417\n",
      "Epoch 518/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7900.2808 - mae: 73.9920 - val_loss: 12950.4785 - val_mae: 97.5358\n",
      "Epoch 519/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7901.0186 - mae: 73.9317 - val_loss: 12840.4805 - val_mae: 97.1626\n",
      "Epoch 520/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7889.3555 - mae: 73.9535 - val_loss: 12879.0371 - val_mae: 97.2850\n",
      "Epoch 521/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7889.7437 - mae: 73.8868 - val_loss: 12930.0693 - val_mae: 97.4371\n",
      "Epoch 522/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7884.4307 - mae: 73.8368 - val_loss: 12935.1348 - val_mae: 97.4738\n",
      "Epoch 523/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7883.1147 - mae: 73.8515 - val_loss: 12933.8467 - val_mae: 97.4529\n",
      "Epoch 524/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7877.6533 - mae: 73.8202 - val_loss: 12872.4756 - val_mae: 97.1742\n",
      "Epoch 525/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7877.2007 - mae: 73.8059 - val_loss: 12899.9561 - val_mae: 97.2804\n",
      "Epoch 526/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7890.5796 - mae: 73.8749 - val_loss: 12941.1240 - val_mae: 97.4734\n",
      "Epoch 527/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7888.4995 - mae: 74.0949 - val_loss: 12601.8584 - val_mae: 96.2517\n",
      "Epoch 528/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7902.2383 - mae: 74.1565 - val_loss: 12728.5322 - val_mae: 96.6725\n",
      "Epoch 529/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 7880.3647 - mae: 73.6669 - val_loss: 13028.4375 - val_mae: 97.8343\n",
      "Epoch 530/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7895.8511 - mae: 73.7043 - val_loss: 13002.9766 - val_mae: 97.7657\n",
      "Epoch 531/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7867.0039 - mae: 73.8150 - val_loss: 12891.2461 - val_mae: 97.3535\n",
      "Epoch 532/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7864.7773 - mae: 73.8582 - val_loss: 12869.4072 - val_mae: 97.2519\n",
      "Epoch 533/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7866.4922 - mae: 73.7102 - val_loss: 13037.5000 - val_mae: 97.8745\n",
      "Epoch 534/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7866.1885 - mae: 73.6819 - val_loss: 12934.4609 - val_mae: 97.4696\n",
      "Epoch 535/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7853.5737 - mae: 73.7176 - val_loss: 12889.0146 - val_mae: 97.2877\n",
      "Epoch 536/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7846.8540 - mae: 73.6226 - val_loss: 12939.3408 - val_mae: 97.4756\n",
      "Epoch 537/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7846.3350 - mae: 73.5326 - val_loss: 12979.0840 - val_mae: 97.6232\n",
      "Epoch 538/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7842.3145 - mae: 73.5714 - val_loss: 12944.0811 - val_mae: 97.4706\n",
      "Epoch 539/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7840.9390 - mae: 73.6027 - val_loss: 12934.8760 - val_mae: 97.4309\n",
      "Epoch 540/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7847.0464 - mae: 73.5730 - val_loss: 12957.5518 - val_mae: 97.5160\n",
      "Epoch 541/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7838.1782 - mae: 73.5802 - val_loss: 12909.4355 - val_mae: 97.3578\n",
      "Epoch 542/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7843.5669 - mae: 73.6903 - val_loss: 13025.9287 - val_mae: 97.7745\n",
      "Epoch 543/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7838.5547 - mae: 73.4312 - val_loss: 13072.4678 - val_mae: 97.9568\n",
      "Epoch 544/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 7836.5830 - mae: 73.3777 - val_loss: 12971.8271 - val_mae: 97.5559\n",
      "Epoch 545/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7825.9248 - mae: 73.4340 - val_loss: 12955.2842 - val_mae: 97.4948\n",
      "Epoch 546/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7832.3062 - mae: 73.5825 - val_loss: 12943.2285 - val_mae: 97.4545\n",
      "Epoch 547/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7815.5483 - mae: 73.4244 - val_loss: 13073.3604 - val_mae: 97.9516\n",
      "Epoch 548/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7826.9795 - mae: 73.3441 - val_loss: 13004.4648 - val_mae: 97.6691\n",
      "Epoch 549/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7820.4468 - mae: 73.2726 - val_loss: 12950.6836 - val_mae: 97.4090\n",
      "Epoch 550/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7824.6792 - mae: 73.3347 - val_loss: 12907.8857 - val_mae: 97.2168\n",
      "Epoch 551/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7813.2710 - mae: 73.3163 - val_loss: 12979.6641 - val_mae: 97.5237\n",
      "Epoch 552/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7813.8105 - mae: 73.3504 - val_loss: 12949.5820 - val_mae: 97.4081\n",
      "Epoch 553/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7808.1958 - mae: 73.2886 - val_loss: 13001.3262 - val_mae: 97.6207\n",
      "Epoch 554/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7805.9600 - mae: 73.3791 - val_loss: 12883.1963 - val_mae: 97.1295\n",
      "Epoch 555/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7810.3857 - mae: 73.4513 - val_loss: 13016.9473 - val_mae: 97.6204\n",
      "Epoch 556/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7800.8745 - mae: 73.3387 - val_loss: 13041.2979 - val_mae: 97.7205\n",
      "Epoch 557/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7804.5347 - mae: 73.3220 - val_loss: 13035.8320 - val_mae: 97.7051\n",
      "Epoch 558/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7792.8354 - mae: 73.2389 - val_loss: 13055.7822 - val_mae: 97.7862\n",
      "Epoch 559/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7805.0259 - mae: 73.1144 - val_loss: 13172.2383 - val_mae: 98.2273\n",
      "Epoch 560/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7789.4507 - mae: 73.0784 - val_loss: 13044.3408 - val_mae: 97.7641\n",
      "Epoch 561/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7789.6235 - mae: 73.2199 - val_loss: 12942.4121 - val_mae: 97.4263\n",
      "Epoch 562/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 7787.3081 - mae: 73.1842 - val_loss: 13008.1875 - val_mae: 97.5882\n",
      "Epoch 563/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7781.9043 - mae: 73.0147 - val_loss: 13107.1855 - val_mae: 97.9057\n",
      "Epoch 564/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7783.8530 - mae: 72.9725 - val_loss: 13120.8379 - val_mae: 97.9820\n",
      "Epoch 565/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7778.0693 - mae: 73.0995 - val_loss: 13061.6650 - val_mae: 97.7524\n",
      "Epoch 566/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7774.2998 - mae: 73.0204 - val_loss: 13063.8057 - val_mae: 97.7610\n",
      "Epoch 567/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7761.6445 - mae: 72.9249 - val_loss: 12859.5967 - val_mae: 96.9601\n",
      "Epoch 568/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7783.7261 - mae: 73.0178 - val_loss: 12884.6963 - val_mae: 97.0033\n",
      "Epoch 569/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7776.3911 - mae: 73.0372 - val_loss: 12939.6973 - val_mae: 97.2323\n",
      "Epoch 570/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7764.1011 - mae: 72.9018 - val_loss: 13124.5967 - val_mae: 97.9721\n",
      "Epoch 571/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7771.6924 - mae: 72.8856 - val_loss: 13146.2539 - val_mae: 98.1029\n",
      "Epoch 572/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7780.7632 - mae: 73.1236 - val_loss: 13030.5410 - val_mae: 97.6457\n",
      "Epoch 573/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7763.1216 - mae: 72.9051 - val_loss: 13125.9248 - val_mae: 98.0112\n",
      "Epoch 574/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7763.4775 - mae: 72.7678 - val_loss: 13014.1279 - val_mae: 97.5774\n",
      "Epoch 575/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7758.4873 - mae: 72.8771 - val_loss: 12991.4805 - val_mae: 97.4764\n",
      "Epoch 576/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7756.4546 - mae: 72.7924 - val_loss: 13059.1064 - val_mae: 97.7314\n",
      "Epoch 577/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 7753.9580 - mae: 72.6530 - val_loss: 13047.0430 - val_mae: 97.7018\n",
      "Epoch 578/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7742.9863 - mae: 72.7783 - val_loss: 12983.9453 - val_mae: 97.4696\n",
      "Epoch 579/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7750.0269 - mae: 72.8424 - val_loss: 13077.1904 - val_mae: 97.8291\n",
      "Epoch 580/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7738.9893 - mae: 72.6658 - val_loss: 13086.5742 - val_mae: 97.8233\n",
      "Epoch 581/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7731.7534 - mae: 72.6451 - val_loss: 13000.2539 - val_mae: 97.4874\n",
      "Epoch 582/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7754.1973 - mae: 72.7143 - val_loss: 12883.0928 - val_mae: 97.0542\n",
      "Epoch 583/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7754.8569 - mae: 72.7183 - val_loss: 12935.2871 - val_mae: 97.2123\n",
      "Epoch 584/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7731.9814 - mae: 72.5807 - val_loss: 13029.9717 - val_mae: 97.5598\n",
      "Epoch 585/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7731.8926 - mae: 72.6775 - val_loss: 12961.3340 - val_mae: 97.2862\n",
      "Epoch 586/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7722.3818 - mae: 72.6489 - val_loss: 13003.2266 - val_mae: 97.4219\n",
      "Epoch 587/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7716.1782 - mae: 72.6436 - val_loss: 13021.9854 - val_mae: 97.5051\n",
      "Epoch 588/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7724.0796 - mae: 72.6833 - val_loss: 13101.4932 - val_mae: 97.7725\n",
      "Epoch 589/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7715.8145 - mae: 72.6444 - val_loss: 13075.5322 - val_mae: 97.6412\n",
      "Epoch 590/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 7712.2495 - mae: 72.5636 - val_loss: 13140.8682 - val_mae: 97.8626\n",
      "Epoch 591/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7721.0996 - mae: 72.5408 - val_loss: 13131.3574 - val_mae: 97.8330\n",
      "Epoch 592/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7744.7563 - mae: 72.8328 - val_loss: 12886.0605 - val_mae: 97.0469\n",
      "Epoch 593/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7718.5869 - mae: 72.6191 - val_loss: 13069.7803 - val_mae: 97.6036\n",
      "Epoch 594/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7711.9233 - mae: 72.3054 - val_loss: 13174.9131 - val_mae: 97.9860\n",
      "Epoch 595/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7701.9375 - mae: 72.3762 - val_loss: 13035.3652 - val_mae: 97.5044\n",
      "Epoch 596/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7701.6396 - mae: 72.4560 - val_loss: 13124.9561 - val_mae: 97.7965\n",
      "Epoch 597/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7691.7197 - mae: 72.3512 - val_loss: 13132.7871 - val_mae: 97.8237\n",
      "Epoch 598/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7690.6143 - mae: 72.3058 - val_loss: 13201.0820 - val_mae: 98.0611\n",
      "Epoch 599/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7699.1445 - mae: 72.3010 - val_loss: 13133.7998 - val_mae: 97.8501\n",
      "Epoch 600/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7685.8882 - mae: 72.2632 - val_loss: 13151.1748 - val_mae: 97.9247\n",
      "Epoch 601/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7687.8818 - mae: 72.1966 - val_loss: 13216.9160 - val_mae: 98.1569\n",
      "Epoch 602/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7684.2847 - mae: 72.2481 - val_loss: 13055.2197 - val_mae: 97.5807\n",
      "Epoch 603/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7694.2607 - mae: 72.3759 - val_loss: 13098.4629 - val_mae: 97.7046\n",
      "Epoch 604/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7682.4634 - mae: 72.1663 - val_loss: 13134.8838 - val_mae: 97.8315\n",
      "Epoch 605/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7683.0532 - mae: 72.2426 - val_loss: 13145.4492 - val_mae: 97.9067\n",
      "Epoch 606/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7685.9600 - mae: 72.1509 - val_loss: 13141.1006 - val_mae: 97.8284\n",
      "Epoch 607/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7694.4072 - mae: 72.2962 - val_loss: 13033.7393 - val_mae: 97.4212\n",
      "Epoch 608/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7675.9155 - mae: 72.1498 - val_loss: 13304.6748 - val_mae: 98.4319\n",
      "Epoch 609/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7687.3804 - mae: 72.1082 - val_loss: 13170.9961 - val_mae: 97.9183\n",
      "Epoch 610/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7673.9009 - mae: 72.2256 - val_loss: 13134.9307 - val_mae: 97.8109\n",
      "Epoch 611/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7671.5142 - mae: 72.0763 - val_loss: 13305.4893 - val_mae: 98.4891\n",
      "Epoch 612/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7669.2388 - mae: 71.9498 - val_loss: 13167.3271 - val_mae: 97.9623\n",
      "Epoch 613/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7665.7354 - mae: 72.2302 - val_loss: 13067.5029 - val_mae: 97.6816\n",
      "Epoch 614/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7661.5796 - mae: 72.2099 - val_loss: 13193.6533 - val_mae: 98.0495\n",
      "Epoch 615/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7662.5229 - mae: 71.9900 - val_loss: 13235.3301 - val_mae: 98.1540\n",
      "Epoch 616/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7652.3989 - mae: 72.0151 - val_loss: 13225.2930 - val_mae: 98.1497\n",
      "Epoch 617/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7647.1938 - mae: 71.9139 - val_loss: 13397.0479 - val_mae: 98.6776\n",
      "Epoch 618/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7654.7227 - mae: 71.9051 - val_loss: 13238.8945 - val_mae: 98.1604\n",
      "Epoch 619/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7645.0527 - mae: 71.8828 - val_loss: 13194.1572 - val_mae: 98.0133\n",
      "Epoch 620/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7639.6597 - mae: 71.9168 - val_loss: 13295.5195 - val_mae: 98.3690\n",
      "Epoch 621/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7634.0308 - mae: 71.8087 - val_loss: 13286.9717 - val_mae: 98.3431\n",
      "Epoch 622/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7637.5483 - mae: 71.8822 - val_loss: 13165.6768 - val_mae: 97.8840\n",
      "Epoch 623/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7637.6548 - mae: 71.8214 - val_loss: 13259.5967 - val_mae: 98.1979\n",
      "Epoch 624/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7633.3057 - mae: 71.7182 - val_loss: 13216.2539 - val_mae: 98.0848\n",
      "Epoch 625/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7626.2534 - mae: 71.7317 - val_loss: 13205.6768 - val_mae: 98.0470\n",
      "Epoch 626/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7625.6929 - mae: 71.6912 - val_loss: 13240.4502 - val_mae: 98.1558\n",
      "Epoch 627/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7620.7402 - mae: 71.6448 - val_loss: 13211.3271 - val_mae: 98.0427\n",
      "Epoch 628/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7621.1260 - mae: 71.7030 - val_loss: 13241.9385 - val_mae: 98.1401\n",
      "Epoch 629/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7617.5195 - mae: 71.6222 - val_loss: 13243.2803 - val_mae: 98.1432\n",
      "Epoch 630/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7614.6787 - mae: 71.6681 - val_loss: 13192.0439 - val_mae: 97.9875\n",
      "Epoch 631/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7615.9663 - mae: 71.5944 - val_loss: 13218.2021 - val_mae: 98.0639\n",
      "Epoch 632/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7613.9258 - mae: 71.6824 - val_loss: 13207.9697 - val_mae: 98.0441\n",
      "Epoch 633/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7610.5317 - mae: 71.6021 - val_loss: 13342.0479 - val_mae: 98.4634\n",
      "Epoch 634/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7613.7485 - mae: 71.4793 - val_loss: 13270.5283 - val_mae: 98.2158\n",
      "Epoch 635/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7613.3413 - mae: 71.6036 - val_loss: 13203.7393 - val_mae: 97.9881\n",
      "Epoch 636/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7602.4175 - mae: 71.5341 - val_loss: 13289.3301 - val_mae: 98.2937\n",
      "Epoch 637/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7608.4204 - mae: 71.3974 - val_loss: 13317.3115 - val_mae: 98.4067\n",
      "Epoch 638/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 7604.6587 - mae: 71.5712 - val_loss: 13203.6396 - val_mae: 98.0273\n",
      "Epoch 639/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7601.7480 - mae: 71.6073 - val_loss: 13302.5039 - val_mae: 98.3336\n",
      "Epoch 640/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7599.6797 - mae: 71.4650 - val_loss: 13296.2695 - val_mae: 98.3586\n",
      "Epoch 641/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7600.8716 - mae: 71.6640 - val_loss: 13153.9590 - val_mae: 97.9497\n",
      "Epoch 642/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7605.0630 - mae: 71.6074 - val_loss: 13350.5518 - val_mae: 98.5496\n",
      "Epoch 643/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7594.5684 - mae: 71.4551 - val_loss: 13273.8516 - val_mae: 98.3290\n",
      "Epoch 644/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7587.2026 - mae: 71.4926 - val_loss: 13362.5498 - val_mae: 98.6800\n",
      "Epoch 645/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7595.3188 - mae: 71.3835 - val_loss: 13380.2480 - val_mae: 98.7066\n",
      "Epoch 646/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7591.9668 - mae: 71.4992 - val_loss: 13278.1982 - val_mae: 98.3950\n",
      "Epoch 647/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7589.0693 - mae: 71.4173 - val_loss: 13379.6787 - val_mae: 98.6720\n",
      "Epoch 648/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7577.2061 - mae: 71.2747 - val_loss: 13370.7021 - val_mae: 98.6354\n",
      "Epoch 649/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7570.9009 - mae: 71.2357 - val_loss: 13396.7803 - val_mae: 98.7012\n",
      "Epoch 650/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7580.9287 - mae: 71.2152 - val_loss: 13374.0762 - val_mae: 98.6338\n",
      "Epoch 651/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7573.6934 - mae: 71.3127 - val_loss: 13300.6348 - val_mae: 98.4400\n",
      "Epoch 652/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7572.2935 - mae: 71.2045 - val_loss: 13399.6035 - val_mae: 98.6908\n",
      "Epoch 653/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7567.7212 - mae: 71.1368 - val_loss: 13340.9297 - val_mae: 98.4915\n",
      "Epoch 654/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7568.3384 - mae: 71.3467 - val_loss: 13332.5234 - val_mae: 98.4653\n",
      "Epoch 655/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7577.2002 - mae: 71.4174 - val_loss: 13372.5127 - val_mae: 98.5235\n",
      "Epoch 656/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7568.5054 - mae: 71.1418 - val_loss: 13469.5723 - val_mae: 98.7712\n",
      "Epoch 657/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7567.3926 - mae: 71.1390 - val_loss: 13284.6104 - val_mae: 98.2074\n",
      "Epoch 658/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7564.7876 - mae: 71.1618 - val_loss: 13450.1367 - val_mae: 98.7062\n",
      "Epoch 659/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7562.0830 - mae: 71.0005 - val_loss: 13376.8408 - val_mae: 98.4896\n",
      "Epoch 660/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7555.4219 - mae: 71.0133 - val_loss: 13406.0957 - val_mae: 98.6444\n",
      "Epoch 661/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7546.7446 - mae: 71.0195 - val_loss: 13469.8057 - val_mae: 98.8593\n",
      "Epoch 662/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7551.0088 - mae: 70.8711 - val_loss: 13474.0801 - val_mae: 98.8559\n",
      "Epoch 663/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7548.1401 - mae: 71.0637 - val_loss: 13273.3633 - val_mae: 98.5150\n",
      "Epoch 664/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7561.9619 - mae: 71.1833 - val_loss: 13354.7148 - val_mae: 98.7347\n",
      "Epoch 665/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7559.0078 - mae: 70.9349 - val_loss: 13470.2432 - val_mae: 99.0086\n",
      "Epoch 666/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7561.5356 - mae: 71.2361 - val_loss: 13339.8086 - val_mae: 98.6323\n",
      "Epoch 667/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7538.4165 - mae: 71.1013 - val_loss: 13597.5068 - val_mae: 99.4434\n",
      "Epoch 668/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7570.8794 - mae: 70.8745 - val_loss: 13456.0996 - val_mae: 98.8477\n",
      "Epoch 669/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7552.3096 - mae: 71.0195 - val_loss: 13200.8838 - val_mae: 98.0201\n",
      "Epoch 670/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7549.6206 - mae: 71.0886 - val_loss: 13322.7910 - val_mae: 98.3568\n",
      "Epoch 671/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7530.2192 - mae: 70.9158 - val_loss: 13477.3340 - val_mae: 99.0199\n",
      "Epoch 672/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7526.9922 - mae: 70.8475 - val_loss: 13585.9697 - val_mae: 99.2955\n",
      "Epoch 673/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7526.7451 - mae: 70.8161 - val_loss: 13533.0908 - val_mae: 99.0504\n",
      "Epoch 674/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7516.9619 - mae: 70.7532 - val_loss: 13462.8271 - val_mae: 98.8197\n",
      "Epoch 675/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7522.5898 - mae: 70.8987 - val_loss: 13357.4570 - val_mae: 98.5381\n",
      "Epoch 676/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7535.5117 - mae: 71.0835 - val_loss: 13428.2412 - val_mae: 98.7342\n",
      "Epoch 677/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7534.1973 - mae: 71.0777 - val_loss: 13446.5166 - val_mae: 98.7974\n",
      "Epoch 678/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7537.3530 - mae: 70.9551 - val_loss: 13528.2109 - val_mae: 99.0991\n",
      "Epoch 679/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7525.1509 - mae: 70.7964 - val_loss: 13377.5771 - val_mae: 98.5789\n",
      "Epoch 680/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7562.1929 - mae: 71.2789 - val_loss: 13248.2480 - val_mae: 98.2648\n",
      "Epoch 681/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7523.5176 - mae: 70.9567 - val_loss: 13575.4629 - val_mae: 99.3753\n",
      "Epoch 682/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7508.4917 - mae: 70.5838 - val_loss: 13514.0352 - val_mae: 99.1468\n",
      "Epoch 683/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7509.2466 - mae: 70.5566 - val_loss: 13401.1006 - val_mae: 98.6446\n",
      "Epoch 684/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7502.8955 - mae: 70.6390 - val_loss: 13405.6211 - val_mae: 98.6691\n",
      "Epoch 685/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7499.3794 - mae: 70.5755 - val_loss: 13570.6914 - val_mae: 99.1823\n",
      "Epoch 686/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7491.4263 - mae: 70.5453 - val_loss: 13459.5088 - val_mae: 98.7546\n",
      "Epoch 687/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7494.5645 - mae: 70.5404 - val_loss: 13511.8105 - val_mae: 99.0051\n",
      "Epoch 688/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7502.9668 - mae: 70.4772 - val_loss: 13518.9834 - val_mae: 98.9564\n",
      "Epoch 689/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7525.0962 - mae: 70.8944 - val_loss: 13374.7363 - val_mae: 98.5811\n",
      "Epoch 690/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7504.8750 - mae: 70.8279 - val_loss: 13570.1143 - val_mae: 99.1238\n",
      "Epoch 691/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7497.5796 - mae: 70.4548 - val_loss: 13627.7998 - val_mae: 99.3501\n",
      "Epoch 692/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7485.6636 - mae: 70.4953 - val_loss: 13428.0117 - val_mae: 98.7935\n",
      "Epoch 693/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7493.6426 - mae: 70.6046 - val_loss: 13427.1533 - val_mae: 98.7664\n",
      "Epoch 694/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7488.8853 - mae: 70.3429 - val_loss: 13524.2715 - val_mae: 99.1636\n",
      "Epoch 695/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7469.7280 - mae: 70.3717 - val_loss: 13512.7324 - val_mae: 99.2490\n",
      "Epoch 696/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7483.4932 - mae: 70.5545 - val_loss: 13538.4570 - val_mae: 99.3722\n",
      "Epoch 697/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7480.7495 - mae: 70.5574 - val_loss: 13453.7324 - val_mae: 98.9617\n",
      "Epoch 698/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7478.5571 - mae: 70.5153 - val_loss: 13490.1016 - val_mae: 99.1230\n",
      "Epoch 699/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7468.9131 - mae: 70.4704 - val_loss: 13440.9482 - val_mae: 98.8609\n",
      "Epoch 700/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7466.7197 - mae: 70.5072 - val_loss: 13483.8105 - val_mae: 99.0603\n",
      "Epoch 701/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7460.4575 - mae: 70.3299 - val_loss: 13541.4072 - val_mae: 99.2711\n",
      "Epoch 702/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7457.0298 - mae: 70.4887 - val_loss: 13476.3818 - val_mae: 99.0037\n",
      "Epoch 703/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7458.4521 - mae: 70.3751 - val_loss: 13626.2676 - val_mae: 99.6242\n",
      "Epoch 704/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7445.0464 - mae: 70.2556 - val_loss: 13383.4463 - val_mae: 98.8000\n",
      "Epoch 705/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7457.9316 - mae: 70.3671 - val_loss: 13474.7217 - val_mae: 99.1021\n",
      "Epoch 706/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7453.1553 - mae: 70.0985 - val_loss: 13621.7109 - val_mae: 99.4914\n",
      "Epoch 707/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7442.2939 - mae: 70.0277 - val_loss: 13565.4580 - val_mae: 99.2795\n",
      "Epoch 708/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7438.1826 - mae: 69.9775 - val_loss: 13684.5586 - val_mae: 99.6988\n",
      "Epoch 709/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7434.0347 - mae: 70.0794 - val_loss: 13499.8750 - val_mae: 99.0551\n",
      "Epoch 710/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7432.0933 - mae: 70.0534 - val_loss: 13624.3213 - val_mae: 99.4425\n",
      "Epoch 711/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7420.7939 - mae: 69.9491 - val_loss: 13565.5518 - val_mae: 99.1562\n",
      "Epoch 712/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7414.2612 - mae: 69.9553 - val_loss: 13634.7432 - val_mae: 99.4834\n",
      "Epoch 713/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7410.9458 - mae: 69.8978 - val_loss: 13604.5234 - val_mae: 99.3703\n",
      "Epoch 714/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7404.5991 - mae: 69.7912 - val_loss: 13590.1865 - val_mae: 99.3009\n",
      "Epoch 715/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7408.6230 - mae: 69.8450 - val_loss: 13517.9570 - val_mae: 98.9922\n",
      "Epoch 716/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7401.8867 - mae: 69.7900 - val_loss: 13640.3125 - val_mae: 99.4691\n",
      "Epoch 717/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7420.8457 - mae: 69.7223 - val_loss: 13665.2158 - val_mae: 99.4553\n",
      "Epoch 718/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7403.6387 - mae: 69.8098 - val_loss: 13406.3086 - val_mae: 98.6618\n",
      "Epoch 719/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7421.0674 - mae: 70.1977 - val_loss: 13568.5342 - val_mae: 99.0641\n",
      "Epoch 720/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7410.0098 - mae: 69.8730 - val_loss: 13766.7324 - val_mae: 99.9008\n",
      "Epoch 721/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7393.8760 - mae: 69.6908 - val_loss: 13581.8447 - val_mae: 99.2256\n",
      "Epoch 722/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7396.5146 - mae: 69.9168 - val_loss: 13640.5234 - val_mae: 99.4236\n",
      "Epoch 723/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7397.8130 - mae: 69.8496 - val_loss: 13622.4766 - val_mae: 99.3027\n",
      "Epoch 724/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7393.3804 - mae: 69.8253 - val_loss: 13592.4072 - val_mae: 99.2451\n",
      "Epoch 725/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7384.7900 - mae: 69.7292 - val_loss: 13694.6377 - val_mae: 99.6812\n",
      "Epoch 726/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7390.0928 - mae: 69.4902 - val_loss: 13655.6367 - val_mae: 99.5990\n",
      "Epoch 727/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7375.8716 - mae: 69.5760 - val_loss: 13513.6211 - val_mae: 98.9797\n",
      "Epoch 728/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7374.3813 - mae: 69.6903 - val_loss: 13697.1182 - val_mae: 99.8975\n",
      "Epoch 729/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7403.1919 - mae: 69.5326 - val_loss: 13812.7373 - val_mae: 100.3894\n",
      "Epoch 730/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7381.5977 - mae: 69.5926 - val_loss: 13519.7217 - val_mae: 98.9956\n",
      "Epoch 731/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7379.5908 - mae: 69.8021 - val_loss: 13559.7480 - val_mae: 99.1205\n",
      "Epoch 732/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7386.4556 - mae: 69.6085 - val_loss: 13909.3125 - val_mae: 100.4138\n",
      "Epoch 733/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7380.3301 - mae: 69.4631 - val_loss: 13515.1338 - val_mae: 98.9888\n",
      "Epoch 734/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7375.4126 - mae: 69.5841 - val_loss: 13523.0000 - val_mae: 99.0354\n",
      "Epoch 735/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7357.6504 - mae: 69.4499 - val_loss: 13716.6318 - val_mae: 99.7297\n",
      "Epoch 736/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7361.3623 - mae: 69.3825 - val_loss: 13864.7002 - val_mae: 100.2507\n",
      "Epoch 737/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7364.2197 - mae: 69.3488 - val_loss: 13847.5605 - val_mae: 100.0986\n",
      "Epoch 738/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7357.8828 - mae: 69.2946 - val_loss: 13660.5859 - val_mae: 99.4244\n",
      "Epoch 739/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7352.0220 - mae: 69.2979 - val_loss: 13716.9697 - val_mae: 99.6293\n",
      "Epoch 740/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7340.9873 - mae: 69.2552 - val_loss: 13689.1982 - val_mae: 99.5303\n",
      "Epoch 741/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7346.2705 - mae: 69.2413 - val_loss: 13696.3115 - val_mae: 99.5925\n",
      "Epoch 742/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7367.0532 - mae: 69.6211 - val_loss: 13575.7754 - val_mae: 99.1318\n",
      "Epoch 743/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7351.1826 - mae: 69.5440 - val_loss: 13795.6260 - val_mae: 99.9960\n",
      "Epoch 744/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7345.9019 - mae: 69.2601 - val_loss: 13771.2393 - val_mae: 99.9780\n",
      "Epoch 745/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7334.2832 - mae: 69.3052 - val_loss: 13611.3604 - val_mae: 99.3214\n",
      "Epoch 746/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7334.4443 - mae: 69.1743 - val_loss: 13919.8857 - val_mae: 100.6341\n",
      "Epoch 747/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7326.7881 - mae: 69.2200 - val_loss: 13773.9912 - val_mae: 99.9699\n",
      "Epoch 748/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7332.1411 - mae: 69.3745 - val_loss: 13780.3193 - val_mae: 100.0706\n",
      "Epoch 749/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7325.8989 - mae: 69.2917 - val_loss: 13678.3213 - val_mae: 99.6127\n",
      "Epoch 750/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7340.8091 - mae: 69.5609 - val_loss: 13649.2324 - val_mae: 99.4521\n",
      "Epoch 751/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7343.7881 - mae: 69.5271 - val_loss: 13855.3037 - val_mae: 100.4481\n",
      "Epoch 752/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7336.0430 - mae: 69.4146 - val_loss: 13794.8896 - val_mae: 100.1890\n",
      "Epoch 753/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7323.9165 - mae: 69.3624 - val_loss: 13675.1289 - val_mae: 99.7678\n",
      "Epoch 754/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 7328.0933 - mae: 69.3154 - val_loss: 13748.9004 - val_mae: 100.2033\n",
      "Epoch 755/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7320.7808 - mae: 69.2358 - val_loss: 13827.5557 - val_mae: 100.4582\n",
      "Epoch 756/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7313.3062 - mae: 69.1611 - val_loss: 13794.8818 - val_mae: 100.1378\n",
      "Epoch 757/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7305.1191 - mae: 69.0675 - val_loss: 13859.3828 - val_mae: 100.3853\n",
      "Epoch 758/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7307.2520 - mae: 68.9065 - val_loss: 13886.5107 - val_mae: 100.3828\n",
      "Epoch 759/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7304.8735 - mae: 68.8606 - val_loss: 13746.4893 - val_mae: 99.7291\n",
      "Epoch 760/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7304.1001 - mae: 69.0539 - val_loss: 13719.5479 - val_mae: 99.6334\n",
      "Epoch 761/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7299.6987 - mae: 69.0379 - val_loss: 13828.4912 - val_mae: 100.0631\n",
      "Epoch 762/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7293.0605 - mae: 68.8586 - val_loss: 13860.4346 - val_mae: 100.2685\n",
      "Epoch 763/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7301.8599 - mae: 68.9120 - val_loss: 13689.1729 - val_mae: 99.7050\n",
      "Epoch 764/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7314.2290 - mae: 68.8590 - val_loss: 13835.9746 - val_mae: 100.2824\n",
      "Epoch 765/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7289.5532 - mae: 68.7805 - val_loss: 13761.3154 - val_mae: 99.9149\n",
      "Epoch 766/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7301.2280 - mae: 69.0818 - val_loss: 13834.8428 - val_mae: 100.1340\n",
      "Epoch 767/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7327.6714 - mae: 68.8334 - val_loss: 14040.6943 - val_mae: 100.7587\n",
      "Epoch 768/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7295.3184 - mae: 68.8109 - val_loss: 13632.9238 - val_mae: 99.3544\n",
      "Epoch 769/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7298.5234 - mae: 69.0616 - val_loss: 13665.2598 - val_mae: 99.4041\n",
      "Epoch 770/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7287.8862 - mae: 68.8065 - val_loss: 13887.8564 - val_mae: 100.0822\n",
      "Epoch 771/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7274.7349 - mae: 68.8391 - val_loss: 13699.8730 - val_mae: 99.4360\n",
      "Epoch 772/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7280.3809 - mae: 69.0602 - val_loss: 13769.5771 - val_mae: 99.7917\n",
      "Epoch 773/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7255.1191 - mae: 68.6233 - val_loss: 13920.5566 - val_mae: 100.5314\n",
      "Epoch 774/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7253.2373 - mae: 68.6354 - val_loss: 13851.9980 - val_mae: 100.1418\n",
      "Epoch 775/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7251.6992 - mae: 68.7184 - val_loss: 13746.0166 - val_mae: 99.7197\n",
      "Epoch 776/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7246.1484 - mae: 68.5465 - val_loss: 13898.1768 - val_mae: 100.3505\n",
      "Epoch 777/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7275.1592 - mae: 68.4143 - val_loss: 14044.4121 - val_mae: 100.9685\n",
      "Epoch 778/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7244.5815 - mae: 68.3868 - val_loss: 13784.7959 - val_mae: 99.8624\n",
      "Epoch 779/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7255.8472 - mae: 68.6300 - val_loss: 14032.1963 - val_mae: 100.8172\n",
      "Epoch 780/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7245.0142 - mae: 68.5809 - val_loss: 13900.8428 - val_mae: 100.3606\n",
      "Epoch 781/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7220.7651 - mae: 68.3676 - val_loss: 14027.8496 - val_mae: 100.9174\n",
      "Epoch 782/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7228.5547 - mae: 68.2761 - val_loss: 13945.2109 - val_mae: 100.3588\n",
      "Epoch 783/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7217.8203 - mae: 68.2657 - val_loss: 13869.5176 - val_mae: 100.0523\n",
      "Epoch 784/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7226.3057 - mae: 68.4887 - val_loss: 13762.4082 - val_mae: 99.7208\n",
      "Epoch 785/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7227.3589 - mae: 68.2718 - val_loss: 13948.4834 - val_mae: 100.6630\n",
      "Epoch 786/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7211.3901 - mae: 68.3286 - val_loss: 13841.7051 - val_mae: 100.2460\n",
      "Epoch 787/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7212.7676 - mae: 68.4444 - val_loss: 13862.9092 - val_mae: 100.1868\n",
      "Epoch 788/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7206.6216 - mae: 68.2372 - val_loss: 13978.6699 - val_mae: 100.7085\n",
      "Epoch 789/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7201.9951 - mae: 68.1131 - val_loss: 13950.1895 - val_mae: 100.5254\n",
      "Epoch 790/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7193.1919 - mae: 68.1087 - val_loss: 13878.6729 - val_mae: 100.2004\n",
      "Epoch 791/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7207.1431 - mae: 68.4091 - val_loss: 13826.7754 - val_mae: 99.9908\n",
      "Epoch 792/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7197.8979 - mae: 68.0921 - val_loss: 14072.8105 - val_mae: 100.9961\n",
      "Epoch 793/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7203.8647 - mae: 68.0809 - val_loss: 13970.6885 - val_mae: 100.6052\n",
      "Epoch 794/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7186.5054 - mae: 68.0733 - val_loss: 14031.7373 - val_mae: 100.8499\n",
      "Epoch 795/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 7181.7466 - mae: 67.9694 - val_loss: 13960.6895 - val_mae: 100.5511\n",
      "Epoch 796/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7188.7739 - mae: 68.0726 - val_loss: 13870.8379 - val_mae: 100.2925\n",
      "Epoch 797/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7194.5869 - mae: 68.0680 - val_loss: 14069.8857 - val_mae: 101.0880\n",
      "Epoch 798/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7181.0083 - mae: 68.0236 - val_loss: 13963.1533 - val_mae: 100.5910\n",
      "Epoch 799/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7174.8325 - mae: 68.0020 - val_loss: 13992.0693 - val_mae: 100.7443\n",
      "Epoch 800/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7173.7539 - mae: 67.8108 - val_loss: 14023.9834 - val_mae: 100.7381\n",
      "Epoch 801/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7169.6138 - mae: 67.7907 - val_loss: 13973.7090 - val_mae: 100.5054\n",
      "Epoch 802/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7171.4487 - mae: 67.8007 - val_loss: 13951.7090 - val_mae: 100.4950\n",
      "Epoch 803/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7173.2925 - mae: 68.1010 - val_loss: 13926.6250 - val_mae: 100.4219\n",
      "Epoch 804/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7175.6030 - mae: 68.0495 - val_loss: 14127.8369 - val_mae: 101.2345\n",
      "Epoch 805/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7174.1064 - mae: 67.8089 - val_loss: 13944.0859 - val_mae: 100.4366\n",
      "Epoch 806/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7167.1738 - mae: 67.9255 - val_loss: 13929.6650 - val_mae: 100.4368\n",
      "Epoch 807/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7167.0815 - mae: 67.7892 - val_loss: 14071.4570 - val_mae: 101.0241\n",
      "Epoch 808/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7158.4009 - mae: 67.8791 - val_loss: 13939.4209 - val_mae: 100.5591\n",
      "Epoch 809/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 7177.0684 - mae: 68.0645 - val_loss: 13994.8682 - val_mae: 100.6533\n",
      "Epoch 810/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7169.4888 - mae: 68.1128 - val_loss: 13837.8398 - val_mae: 100.1978\n",
      "Epoch 811/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7165.0005 - mae: 68.0108 - val_loss: 13972.1426 - val_mae: 100.8253\n",
      "Epoch 812/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7157.7817 - mae: 67.8066 - val_loss: 13958.4287 - val_mae: 100.8327\n",
      "Epoch 813/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7153.4258 - mae: 67.7613 - val_loss: 14004.8193 - val_mae: 101.0587\n",
      "Epoch 814/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7146.8330 - mae: 67.7050 - val_loss: 13918.2051 - val_mae: 100.6274\n",
      "Epoch 815/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7142.1484 - mae: 67.7788 - val_loss: 14081.5908 - val_mae: 101.3571\n",
      "Epoch 816/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7140.2617 - mae: 67.5653 - val_loss: 14015.8457 - val_mae: 101.0686\n",
      "Epoch 817/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7135.4385 - mae: 67.6235 - val_loss: 13940.7842 - val_mae: 100.7682\n",
      "Epoch 818/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7131.1792 - mae: 67.5118 - val_loss: 14009.7207 - val_mae: 101.0295\n",
      "Epoch 819/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7147.6680 - mae: 67.5514 - val_loss: 13934.7002 - val_mae: 100.4938\n",
      "Epoch 820/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7137.5479 - mae: 67.7108 - val_loss: 14003.2529 - val_mae: 100.6976\n",
      "Epoch 821/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7132.2944 - mae: 67.5653 - val_loss: 14107.2539 - val_mae: 101.2170\n",
      "Epoch 822/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7121.3086 - mae: 67.3385 - val_loss: 14026.8232 - val_mae: 100.8983\n",
      "Epoch 823/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7128.0620 - mae: 67.5849 - val_loss: 13958.5195 - val_mae: 100.6498\n",
      "Epoch 824/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7116.8750 - mae: 67.5008 - val_loss: 14073.2715 - val_mae: 101.1804\n",
      "Epoch 825/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7116.6567 - mae: 67.4374 - val_loss: 13891.3711 - val_mae: 100.3204\n",
      "Epoch 826/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7125.6392 - mae: 67.6397 - val_loss: 13933.7461 - val_mae: 100.5204\n",
      "Epoch 827/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7116.1763 - mae: 67.4973 - val_loss: 14172.6797 - val_mae: 101.6128\n",
      "Epoch 828/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7124.0659 - mae: 67.4205 - val_loss: 14041.2354 - val_mae: 101.0040\n",
      "Epoch 829/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7133.4619 - mae: 67.7667 - val_loss: 13793.4961 - val_mae: 99.9255\n",
      "Epoch 830/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7122.6094 - mae: 67.5633 - val_loss: 14104.4248 - val_mae: 101.0966\n",
      "Epoch 831/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7111.7441 - mae: 67.2788 - val_loss: 14113.0547 - val_mae: 101.1552\n",
      "Epoch 832/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7105.8999 - mae: 67.2850 - val_loss: 14013.1797 - val_mae: 100.7994\n",
      "Epoch 833/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7139.1089 - mae: 67.8499 - val_loss: 13751.0322 - val_mae: 99.7523\n",
      "Epoch 834/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7121.9717 - mae: 67.7631 - val_loss: 14209.1074 - val_mae: 101.5696\n",
      "Epoch 835/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7152.2559 - mae: 67.3536 - val_loss: 14245.3555 - val_mae: 101.6972\n",
      "Epoch 836/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7128.6533 - mae: 67.5661 - val_loss: 13770.5879 - val_mae: 99.7567\n",
      "Epoch 837/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7114.6636 - mae: 67.5442 - val_loss: 14066.1875 - val_mae: 100.9422\n",
      "Epoch 838/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7121.9951 - mae: 67.2785 - val_loss: 14029.9932 - val_mae: 100.6250\n",
      "Epoch 839/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7111.5596 - mae: 67.2378 - val_loss: 14112.3730 - val_mae: 100.7077\n",
      "Epoch 840/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7109.7393 - mae: 67.1703 - val_loss: 14158.2744 - val_mae: 100.8275\n",
      "Epoch 841/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7108.3926 - mae: 67.3018 - val_loss: 13990.1963 - val_mae: 100.3128\n",
      "Epoch 842/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7085.5835 - mae: 67.1504 - val_loss: 14166.8623 - val_mae: 101.1805\n",
      "Epoch 843/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7088.6626 - mae: 67.0138 - val_loss: 14154.4072 - val_mae: 101.1476\n",
      "Epoch 844/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7080.5767 - mae: 66.9875 - val_loss: 14197.4521 - val_mae: 101.3123\n",
      "Epoch 845/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 7077.0229 - mae: 66.9655 - val_loss: 14005.9053 - val_mae: 100.6639\n",
      "Epoch 846/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7081.6987 - mae: 67.1320 - val_loss: 14080.1006 - val_mae: 101.0014\n",
      "Epoch 847/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7084.4468 - mae: 66.9629 - val_loss: 14213.0010 - val_mae: 101.4711\n",
      "Epoch 848/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7071.3979 - mae: 66.8917 - val_loss: 14034.0908 - val_mae: 100.6468\n",
      "Epoch 849/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7078.0815 - mae: 67.0919 - val_loss: 14070.8818 - val_mae: 100.7205\n",
      "Epoch 850/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7070.5249 - mae: 66.8923 - val_loss: 14142.9189 - val_mae: 101.0367\n",
      "Epoch 851/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7066.6890 - mae: 66.8744 - val_loss: 14119.8477 - val_mae: 100.9833\n",
      "Epoch 852/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7063.3643 - mae: 66.8051 - val_loss: 14249.2002 - val_mae: 101.5904\n",
      "Epoch 853/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7057.5068 - mae: 66.8336 - val_loss: 14109.4141 - val_mae: 101.1221\n",
      "Epoch 854/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7057.4604 - mae: 66.8188 - val_loss: 14120.3506 - val_mae: 101.1107\n",
      "Epoch 855/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7059.1167 - mae: 66.7808 - val_loss: 14217.6250 - val_mae: 101.2519\n",
      "Epoch 856/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7061.4390 - mae: 66.7340 - val_loss: 14246.6934 - val_mae: 101.3515\n",
      "Epoch 857/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7057.8252 - mae: 66.7504 - val_loss: 14275.4492 - val_mae: 101.5988\n",
      "Epoch 858/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7054.2148 - mae: 66.7522 - val_loss: 14127.5762 - val_mae: 101.0779\n",
      "Epoch 859/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7061.4331 - mae: 67.1229 - val_loss: 13964.5605 - val_mae: 100.4070\n",
      "Epoch 860/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7067.2925 - mae: 67.1955 - val_loss: 14384.0967 - val_mae: 102.1243\n",
      "Epoch 861/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7068.2397 - mae: 66.7818 - val_loss: 14174.2109 - val_mae: 101.3652\n",
      "Epoch 862/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7047.1201 - mae: 66.8562 - val_loss: 14054.9570 - val_mae: 100.9322\n",
      "Epoch 863/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7050.3252 - mae: 66.9007 - val_loss: 14114.9912 - val_mae: 101.1782\n",
      "Epoch 864/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7048.2275 - mae: 66.7668 - val_loss: 14207.8066 - val_mae: 101.4851\n",
      "Epoch 865/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7038.2129 - mae: 66.6718 - val_loss: 14166.4355 - val_mae: 101.2106\n",
      "Epoch 866/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7032.1245 - mae: 66.5855 - val_loss: 14253.4355 - val_mae: 101.5395\n",
      "Epoch 867/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7033.2085 - mae: 66.5580 - val_loss: 14294.3193 - val_mae: 101.7679\n",
      "Epoch 868/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7044.3994 - mae: 66.7588 - val_loss: 14225.1250 - val_mae: 101.6314\n",
      "Epoch 869/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7033.0957 - mae: 66.6603 - val_loss: 14308.4160 - val_mae: 101.8903\n",
      "Epoch 870/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7036.7969 - mae: 66.5590 - val_loss: 14206.7568 - val_mae: 101.3185\n",
      "Epoch 871/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7028.8643 - mae: 66.5903 - val_loss: 14133.0479 - val_mae: 100.9889\n",
      "Epoch 872/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7037.0815 - mae: 66.6064 - val_loss: 14078.9648 - val_mae: 100.9198\n",
      "Epoch 873/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7028.9155 - mae: 66.4724 - val_loss: 14128.8535 - val_mae: 101.1509\n",
      "Epoch 874/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7018.4883 - mae: 66.4548 - val_loss: 14252.1562 - val_mae: 101.5931\n",
      "Epoch 875/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7024.3262 - mae: 66.4367 - val_loss: 14249.2119 - val_mae: 101.6100\n",
      "Epoch 876/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7024.8042 - mae: 66.5940 - val_loss: 14048.2051 - val_mae: 100.8516\n",
      "Epoch 877/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7021.7344 - mae: 66.4793 - val_loss: 14233.8643 - val_mae: 101.5741\n",
      "Epoch 878/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7016.6812 - mae: 66.3460 - val_loss: 14216.9746 - val_mae: 101.3465\n",
      "Epoch 879/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7011.7178 - mae: 66.4333 - val_loss: 14232.6631 - val_mae: 101.3507\n",
      "Epoch 880/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7017.7412 - mae: 66.4530 - val_loss: 14276.2705 - val_mae: 101.5247\n",
      "Epoch 881/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7022.9214 - mae: 66.5537 - val_loss: 14030.0273 - val_mae: 100.4796\n",
      "Epoch 882/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7020.5420 - mae: 66.4785 - val_loss: 14212.9463 - val_mae: 101.1059\n",
      "Epoch 883/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7033.2036 - mae: 66.2689 - val_loss: 14250.6787 - val_mae: 101.2106\n",
      "Epoch 884/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7023.4126 - mae: 66.5486 - val_loss: 13995.7734 - val_mae: 100.4507\n",
      "Epoch 885/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7028.5356 - mae: 66.6690 - val_loss: 14154.9141 - val_mae: 100.9084\n",
      "Epoch 886/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7015.6729 - mae: 66.4539 - val_loss: 14275.6875 - val_mae: 101.4260\n",
      "Epoch 887/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7012.5767 - mae: 66.3970 - val_loss: 14333.3193 - val_mae: 101.5819\n",
      "Epoch 888/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7009.2349 - mae: 66.4045 - val_loss: 14300.5342 - val_mae: 101.4212\n",
      "Epoch 889/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6996.6807 - mae: 66.2995 - val_loss: 14360.5498 - val_mae: 101.7112\n",
      "Epoch 890/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6999.8477 - mae: 66.2415 - val_loss: 14244.9082 - val_mae: 101.2682\n",
      "Epoch 891/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7006.0762 - mae: 66.4415 - val_loss: 14217.3242 - val_mae: 101.2204\n",
      "Epoch 892/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6996.7402 - mae: 66.1556 - val_loss: 14362.8086 - val_mae: 101.8026\n",
      "Epoch 893/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 6998.5156 - mae: 66.2061 - val_loss: 14171.5518 - val_mae: 101.1073\n",
      "Epoch 894/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6989.9292 - mae: 66.2430 - val_loss: 14280.4746 - val_mae: 101.4375\n",
      "Epoch 895/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6993.1357 - mae: 66.1614 - val_loss: 14300.6143 - val_mae: 101.4639\n",
      "Epoch 896/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6989.0068 - mae: 66.0656 - val_loss: 14233.3242 - val_mae: 101.1949\n",
      "Epoch 897/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6999.2007 - mae: 66.4001 - val_loss: 14065.0635 - val_mae: 100.6358\n",
      "Epoch 898/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6993.2695 - mae: 66.3394 - val_loss: 14275.3379 - val_mae: 101.3754\n",
      "Epoch 899/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7013.8706 - mae: 66.1198 - val_loss: 14335.6943 - val_mae: 101.5640\n",
      "Epoch 900/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7002.4297 - mae: 66.4239 - val_loss: 14034.9766 - val_mae: 100.6385\n",
      "Epoch 901/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6983.2769 - mae: 66.2385 - val_loss: 14308.1348 - val_mae: 101.7095\n",
      "Epoch 902/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6989.5449 - mae: 66.1922 - val_loss: 14303.2051 - val_mae: 101.5342\n",
      "Epoch 903/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6981.7637 - mae: 66.1241 - val_loss: 14332.5537 - val_mae: 101.5906\n",
      "Epoch 904/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6976.4067 - mae: 66.0828 - val_loss: 14196.8994 - val_mae: 101.1491\n",
      "Epoch 905/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6969.8164 - mae: 66.0091 - val_loss: 14392.1797 - val_mae: 101.9158\n",
      "Epoch 906/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6979.3574 - mae: 66.0520 - val_loss: 14300.8535 - val_mae: 101.5998\n",
      "Epoch 907/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6986.9585 - mae: 65.9914 - val_loss: 14401.4873 - val_mae: 101.8885\n",
      "Epoch 908/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6968.2271 - mae: 65.9204 - val_loss: 14180.1387 - val_mae: 101.1252\n",
      "Epoch 909/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6979.3564 - mae: 66.2613 - val_loss: 14191.9688 - val_mae: 101.3584\n",
      "Epoch 910/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6972.0522 - mae: 66.1032 - val_loss: 14422.1416 - val_mae: 102.3575\n",
      "Epoch 911/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6989.1919 - mae: 66.0316 - val_loss: 14344.6768 - val_mae: 101.8305\n",
      "Epoch 912/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6972.0078 - mae: 66.0123 - val_loss: 14137.6465 - val_mae: 100.8176\n",
      "Epoch 913/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6971.9028 - mae: 65.9996 - val_loss: 14406.3027 - val_mae: 101.7175\n",
      "Epoch 914/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6969.8970 - mae: 65.7536 - val_loss: 14350.1533 - val_mae: 101.6524\n",
      "Epoch 915/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6959.4106 - mae: 65.8318 - val_loss: 14187.9746 - val_mae: 101.2376\n",
      "Epoch 916/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6957.0405 - mae: 65.7696 - val_loss: 14320.7129 - val_mae: 101.7085\n",
      "Epoch 917/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 6959.5850 - mae: 65.8998 - val_loss: 14234.2754 - val_mae: 101.4115\n",
      "Epoch 918/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6945.6094 - mae: 65.7816 - val_loss: 14511.4375 - val_mae: 102.4415\n",
      "Epoch 919/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 6949.6460 - mae: 65.7670 - val_loss: 14299.8672 - val_mae: 101.5681\n",
      "Epoch 920/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6950.9419 - mae: 65.8479 - val_loss: 14255.8955 - val_mae: 101.4060\n",
      "Epoch 921/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6945.0723 - mae: 65.7680 - val_loss: 14428.2949 - val_mae: 101.9889\n",
      "Epoch 922/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6958.6196 - mae: 65.6933 - val_loss: 14455.1016 - val_mae: 102.1818\n",
      "Epoch 923/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6957.7124 - mae: 65.8893 - val_loss: 14328.3447 - val_mae: 101.7302\n",
      "Epoch 924/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6943.7793 - mae: 65.7967 - val_loss: 14449.8105 - val_mae: 101.9225\n",
      "Epoch 925/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6940.8770 - mae: 65.5765 - val_loss: 14507.0000 - val_mae: 102.0879\n",
      "Epoch 926/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6935.7949 - mae: 65.5561 - val_loss: 14534.0303 - val_mae: 102.2182\n",
      "Epoch 927/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6934.3325 - mae: 65.6075 - val_loss: 14511.2432 - val_mae: 102.1660\n",
      "Epoch 928/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 6934.8359 - mae: 65.6707 - val_loss: 14368.8447 - val_mae: 101.6370\n",
      "Epoch 929/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6939.4180 - mae: 65.7210 - val_loss: 14438.5254 - val_mae: 101.8486\n",
      "Epoch 930/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6927.4102 - mae: 65.5606 - val_loss: 14471.9053 - val_mae: 101.9839\n",
      "Epoch 931/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6928.7539 - mae: 65.5331 - val_loss: 14452.7246 - val_mae: 101.9731\n",
      "Epoch 932/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6928.0854 - mae: 65.6670 - val_loss: 14386.8184 - val_mae: 101.7663\n",
      "Epoch 933/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6917.8267 - mae: 65.4973 - val_loss: 14557.6768 - val_mae: 102.3328\n",
      "Epoch 934/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6927.0776 - mae: 65.4632 - val_loss: 14475.7822 - val_mae: 102.1060\n",
      "Epoch 935/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6918.5400 - mae: 65.4570 - val_loss: 14483.1074 - val_mae: 102.1311\n",
      "Epoch 936/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6922.1436 - mae: 65.6862 - val_loss: 14406.8662 - val_mae: 101.9483\n",
      "Epoch 937/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6939.3281 - mae: 65.5162 - val_loss: 14600.9766 - val_mae: 102.5880\n",
      "Epoch 938/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 6912.2783 - mae: 65.3803 - val_loss: 14398.4258 - val_mae: 101.9501\n",
      "Epoch 939/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6915.4980 - mae: 65.5065 - val_loss: 14440.6035 - val_mae: 102.1641\n",
      "Epoch 940/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6913.5977 - mae: 65.3790 - val_loss: 14486.1182 - val_mae: 102.4290\n",
      "Epoch 941/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6910.9048 - mae: 65.3664 - val_loss: 14601.6582 - val_mae: 102.7500\n",
      "Epoch 942/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6904.9644 - mae: 65.2973 - val_loss: 14491.9521 - val_mae: 102.3414\n",
      "Epoch 943/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6902.7026 - mae: 65.2816 - val_loss: 14487.3145 - val_mae: 102.2789\n",
      "Epoch 944/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6900.3257 - mae: 65.2476 - val_loss: 14452.8564 - val_mae: 102.2508\n",
      "Epoch 945/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6908.6982 - mae: 65.5012 - val_loss: 14418.9893 - val_mae: 102.2008\n",
      "Epoch 946/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6903.7515 - mae: 65.4283 - val_loss: 14585.5898 - val_mae: 102.8118\n",
      "Epoch 947/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6906.8359 - mae: 65.2498 - val_loss: 14463.9258 - val_mae: 102.3042\n",
      "Epoch 948/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6899.3716 - mae: 65.2790 - val_loss: 14419.6016 - val_mae: 102.1080\n",
      "Epoch 949/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6891.1890 - mae: 65.1204 - val_loss: 14528.1230 - val_mae: 102.3708\n",
      "Epoch 950/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 6898.3091 - mae: 65.1270 - val_loss: 14464.6621 - val_mae: 102.1883\n",
      "Epoch 951/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6895.3765 - mae: 65.3122 - val_loss: 14450.3750 - val_mae: 102.2243\n",
      "Epoch 952/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6898.1382 - mae: 65.1608 - val_loss: 14584.7295 - val_mae: 102.5850\n",
      "Epoch 953/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6895.6763 - mae: 65.1113 - val_loss: 14590.4824 - val_mae: 102.5353\n",
      "Epoch 954/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6889.0176 - mae: 65.1968 - val_loss: 14445.0840 - val_mae: 102.2542\n",
      "Epoch 955/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6902.1816 - mae: 65.1346 - val_loss: 14487.3242 - val_mae: 102.5129\n",
      "Epoch 956/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6889.6260 - mae: 65.2507 - val_loss: 14395.9463 - val_mae: 102.1617\n",
      "Epoch 957/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6888.3813 - mae: 65.1796 - val_loss: 14564.6084 - val_mae: 102.5843\n",
      "Epoch 958/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6881.5220 - mae: 65.0662 - val_loss: 14467.5166 - val_mae: 102.2521\n",
      "Epoch 959/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 6907.5278 - mae: 65.5342 - val_loss: 14310.2959 - val_mae: 101.8864\n",
      "Epoch 960/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6901.0200 - mae: 65.4101 - val_loss: 14652.0254 - val_mae: 103.0270\n",
      "Epoch 961/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6876.6016 - mae: 64.9853 - val_loss: 14401.6865 - val_mae: 102.0084\n",
      "Epoch 962/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6874.8228 - mae: 64.9838 - val_loss: 14464.6104 - val_mae: 102.0888\n",
      "Epoch 963/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6881.0039 - mae: 65.0790 - val_loss: 14494.2324 - val_mae: 102.1345\n",
      "Epoch 964/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6873.7944 - mae: 64.9677 - val_loss: 14620.3027 - val_mae: 102.5281\n",
      "Epoch 965/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6882.6748 - mae: 65.1358 - val_loss: 14471.1504 - val_mae: 102.0023\n",
      "Epoch 966/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6887.0239 - mae: 65.1463 - val_loss: 14594.7842 - val_mae: 102.4682\n",
      "Epoch 967/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6892.0269 - mae: 65.2488 - val_loss: 14243.7109 - val_mae: 101.3865\n",
      "Epoch 968/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6874.7144 - mae: 65.0946 - val_loss: 14559.4658 - val_mae: 102.4305\n",
      "Epoch 969/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6872.8833 - mae: 64.9443 - val_loss: 14455.2158 - val_mae: 102.0973\n",
      "Epoch 970/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6884.7183 - mae: 65.2192 - val_loss: 14736.7930 - val_mae: 103.0448\n",
      "Epoch 971/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 6867.1489 - mae: 64.9368 - val_loss: 14587.6426 - val_mae: 102.5892\n",
      "Epoch 972/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6866.0415 - mae: 64.8603 - val_loss: 14502.4805 - val_mae: 102.2432\n",
      "Epoch 973/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6879.5146 - mae: 64.9332 - val_loss: 14485.0146 - val_mae: 102.1745\n",
      "Epoch 974/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6867.1113 - mae: 64.9351 - val_loss: 14618.2305 - val_mae: 102.7087\n",
      "Epoch 975/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6897.8403 - mae: 65.4761 - val_loss: 14352.8428 - val_mae: 101.9946\n",
      "Epoch 976/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6886.8799 - mae: 65.3281 - val_loss: 14739.5801 - val_mae: 102.9987\n",
      "Epoch 977/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6872.4360 - mae: 64.9425 - val_loss: 14554.4443 - val_mae: 102.4211\n",
      "Epoch 978/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6855.3120 - mae: 64.8310 - val_loss: 14562.9336 - val_mae: 102.5267\n",
      "Epoch 979/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6851.3643 - mae: 64.8678 - val_loss: 14564.6250 - val_mae: 102.6512\n",
      "Epoch 980/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6850.3262 - mae: 64.8863 - val_loss: 14526.8770 - val_mae: 102.5452\n",
      "Epoch 981/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6856.4395 - mae: 64.8643 - val_loss: 14455.9893 - val_mae: 102.1217\n",
      "Epoch 982/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6860.5156 - mae: 64.8326 - val_loss: 14510.1934 - val_mae: 102.2311\n",
      "Epoch 983/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 6845.6631 - mae: 64.7153 - val_loss: 14557.8301 - val_mae: 102.4634\n",
      "Epoch 984/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6852.6675 - mae: 64.9705 - val_loss: 14505.2354 - val_mae: 102.3364\n",
      "Epoch 985/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6852.3145 - mae: 64.9640 - val_loss: 14703.4570 - val_mae: 102.8161\n",
      "Epoch 986/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6845.4526 - mae: 64.7409 - val_loss: 14720.7676 - val_mae: 102.8726\n",
      "Epoch 987/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6850.1426 - mae: 64.7326 - val_loss: 14631.3301 - val_mae: 102.7339\n",
      "Epoch 988/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6840.7266 - mae: 64.7871 - val_loss: 14597.3359 - val_mae: 102.6510\n",
      "Epoch 989/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6849.3755 - mae: 64.9015 - val_loss: 14809.3564 - val_mae: 103.3994\n",
      "Epoch 990/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6837.5146 - mae: 64.7360 - val_loss: 14603.5186 - val_mae: 102.6856\n",
      "Epoch 991/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6840.9990 - mae: 64.7202 - val_loss: 14498.8203 - val_mae: 102.2707\n",
      "Epoch 992/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6837.0239 - mae: 64.6704 - val_loss: 14725.7637 - val_mae: 102.8596\n",
      "Epoch 993/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6863.3110 - mae: 64.6620 - val_loss: 14784.4375 - val_mae: 103.1504\n",
      "Epoch 994/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6827.9712 - mae: 64.6352 - val_loss: 14614.7432 - val_mae: 102.6121\n",
      "Epoch 995/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6836.0098 - mae: 64.7344 - val_loss: 14799.7178 - val_mae: 103.1962\n",
      "Epoch 996/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6831.0298 - mae: 64.5681 - val_loss: 14557.6768 - val_mae: 102.4985\n",
      "Epoch 997/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6828.2026 - mae: 64.6057 - val_loss: 14630.8086 - val_mae: 102.7081\n",
      "Epoch 998/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6835.3599 - mae: 64.5336 - val_loss: 14799.1660 - val_mae: 103.2386\n",
      "Epoch 999/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6828.1162 - mae: 64.5430 - val_loss: 14540.7754 - val_mae: 102.4089\n",
      "Epoch 1000/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6824.3506 - mae: 64.5714 - val_loss: 14656.3398 - val_mae: 102.7565\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 18356.5273 - mae: 113.2653\n",
      "Mean Absolute Error on Test Set: 113.26531982421875\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000166FA45B160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=1000, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Mean Absolute Error on Test Set: {mae}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34495637],\n",
       "       [-0.40295032],\n",
       "       [ 0.17824353],\n",
       "       ...,\n",
       "       [ 0.48004445],\n",
       "       [-0.29392853],\n",
       "       [ 0.5742067 ]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
